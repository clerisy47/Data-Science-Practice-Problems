{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use digits mnist dataset and fashion mnist dataset to build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = digits.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f911809c520>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(20, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 20)                15700     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,910\n",
      "Trainable params: 15,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",           \n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 653us/step - loss: 0.4016 - accuracy: 0.8875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91aa4ea220>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 533us/step - loss: 0.2500 - accuracy: 0.9291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24997609853744507, 0.929099977016449]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f91885e92e0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 441us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f91bf59dd90>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[train_labels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hidden_layers=1):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(500, activation=\"relu\"),\n",
    "        keras.layers.Dense(10, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4723 - accuracy: 0.8297\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3570 - accuracy: 0.8691\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3204 - accuracy: 0.8828\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3003 - accuracy: 0.8887\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2793 - accuracy: 0.8967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9199548970>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(1)\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[test_labels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[np.argmax(model.predict(test_images)[0])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take this dataset for bank customer churn prediction : https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
    "\n",
    "i. Build a deep learning model to predict churn rate at bank. <br>\n",
    "ii. Once model is built, print classification report and analyze precision, recall and f1-score <br>\n",
    "iii. Improve f1 score in minority class using various techniques such as undersampling, oversampling, ensemble etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>6854</td>\n",
       "      <td>15593943</td>\n",
       "      <td>Chinagorom</td>\n",
       "      <td>685</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>132667.17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41876.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>2724</td>\n",
       "      <td>15681550</td>\n",
       "      <td>Lablanc</td>\n",
       "      <td>614</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>121558.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>598.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>2349</td>\n",
       "      <td>15775203</td>\n",
       "      <td>Chia</td>\n",
       "      <td>824</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>129209.48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60151.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>1492</td>\n",
       "      <td>15634891</td>\n",
       "      <td>Jamison</td>\n",
       "      <td>504</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>102365.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>194690.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9032</th>\n",
       "      <td>9033</td>\n",
       "      <td>15658435</td>\n",
       "      <td>Hingston</td>\n",
       "      <td>781</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72969.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId     Surname  CreditScore Geography  Gender  Age  \\\n",
       "6853       6854    15593943  Chinagorom          685    France  Female   43   \n",
       "2723       2724    15681550     Lablanc          614    France  Female   41   \n",
       "2348       2349    15775203        Chia          824    France    Male   45   \n",
       "1491       1492    15634891     Jamison          504   Germany  Female   43   \n",
       "9032       9033    15658435    Hingston          781    France  Female   27   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "6853       1  132667.17              1          1               1   \n",
       "2723       8  121558.46              1          1               1   \n",
       "2348       3  129209.48              1          0               0   \n",
       "1491       7  102365.49              1          1               0   \n",
       "9032       5       0.00              2          0               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "6853         41876.98       0  \n",
       "2723           598.80       0  \n",
       "2348         60151.77       0  \n",
       "1491        194690.77       1  \n",
       "9032         72969.90       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6228</th>\n",
       "      <td>663</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>90248.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79169.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>607</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>102609.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>163257.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9789</th>\n",
       "      <td>610</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199657.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>687</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>152328.88</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126494.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9647</th>\n",
       "      <td>625</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "6228          663   Germany    Male   42       5   90248.79              1   \n",
       "9731          607   Germany    Male   29       7  102609.00              1   \n",
       "9789          610    France  Female   45       1       0.00              2   \n",
       "61            687   Germany  Female   27       9  152328.88              2   \n",
       "9647          625    France    Male   31       5       0.00              2   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "6228          1               1         79169.73       0  \n",
       "9731          1               0        163257.44       0  \n",
       "9789          1               1        199657.46       0  \n",
       "61            0               0        126494.82       0  \n",
       "9647          0               1            90.07       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped = df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1)\n",
    "df_dropped.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1                  0   \n",
       "1                  1        112542.58       0                  0   \n",
       "2                  0        113931.57       1                  0   \n",
       "3                  0         93826.63       0                  0   \n",
       "4                  1         79084.10       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0                  0   \n",
       "9996               1        101699.77       0                  0   \n",
       "9997               1         42085.58       1                  0   \n",
       "9998               0         92888.52       1                  1   \n",
       "9999               0         38190.78       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_dummies = pd.get_dummies(data=df_dropped, drop_first=True)\n",
    "df_with_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore            int64\n",
       "Age                    int64\n",
       "Tenure                 int64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Exited                 int64\n",
       "Geography_Germany      uint8\n",
       "Geography_Spain        uint8\n",
       "Gender_Male            uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_dummies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0           0.538  0.324324     0.2  0.000000       0.000000          1   \n",
       "1           0.516  0.310811     0.1  0.334031       0.000000          0   \n",
       "2           0.304  0.324324     0.8  0.636357       0.666667          1   \n",
       "3           0.698  0.283784     0.1  0.000000       0.333333          0   \n",
       "4           1.000  0.337838     0.2  0.500246       0.000000          1   \n",
       "...           ...       ...     ...       ...            ...        ...   \n",
       "9995        0.842  0.283784     0.5  0.000000       0.333333          1   \n",
       "9996        0.332  0.229730     1.0  0.228657       0.000000          1   \n",
       "9997        0.718  0.243243     0.7  0.000000       0.000000          0   \n",
       "9998        0.844  0.324324     0.3  0.299226       0.333333          1   \n",
       "9999        0.884  0.135135     0.4  0.518708       0.000000          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1         0.506735       1                  0   \n",
       "1                  1         0.562709       0                  0   \n",
       "2                  0         0.569654       1                  0   \n",
       "3                  0         0.469120       0                  0   \n",
       "4                  1         0.395400       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         0.481341       0                  0   \n",
       "9996               1         0.508490       0                  0   \n",
       "9997               1         0.210390       1                  0   \n",
       "9998               0         0.464429       1                  1   \n",
       "9999               0         0.190914       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "columns_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = MinMaxScaler()\n",
    "df_with_dummies[columns_to_scale] = scaler.fit_transform(df_with_dummies[columns_to_scale])\n",
    "df_with_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_with_dummies.drop(\"Exited\", axis=1)\n",
    "y = df_with_dummies[\"Exited\"]\n",
    "X_test, X_train, y_test, y_train= train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, X_test, y_train, y_test):\n",
    "    model= keras.Sequential([\n",
    "        keras.layers.Dense(11, activation='relu', input_dim=11),\n",
    "        keras.layers.Dense(5, activation='relu'),\n",
    "        keras.layers.Dense(1, activation= 'sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100)\n",
    "    model.evaluate(X_test, y_test)\n",
    "    y_pred= np.round(model.predict(X_test))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return y_pred\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 835us/step - loss: 0.7792 - accuracy: 0.2730\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.5980\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 723us/step - loss: 0.5775 - accuracy: 0.7915\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 732us/step - loss: 0.5232 - accuracy: 0.7965\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 733us/step - loss: 0.5117 - accuracy: 0.7965\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 727us/step - loss: 0.5048 - accuracy: 0.7965\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 734us/step - loss: 0.4987 - accuracy: 0.7965\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 771us/step - loss: 0.4918 - accuracy: 0.7965\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 776us/step - loss: 0.4830 - accuracy: 0.7965\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 746us/step - loss: 0.4735 - accuracy: 0.7965\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 734us/step - loss: 0.4658 - accuracy: 0.7965\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.4596 - accuracy: 0.7965\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 701us/step - loss: 0.4553 - accuracy: 0.7990\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.4507 - accuracy: 0.8055\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 782us/step - loss: 0.4482 - accuracy: 0.8070\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 717us/step - loss: 0.4459 - accuracy: 0.8080\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 721us/step - loss: 0.4432 - accuracy: 0.8100\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 713us/step - loss: 0.4411 - accuracy: 0.8125\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 699us/step - loss: 0.4384 - accuracy: 0.8175\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 800us/step - loss: 0.4366 - accuracy: 0.8170\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 676us/step - loss: 0.4339 - accuracy: 0.8135\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 705us/step - loss: 0.4332 - accuracy: 0.8125\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 715us/step - loss: 0.4303 - accuracy: 0.8170\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 696us/step - loss: 0.4292 - accuracy: 0.8160\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.4269 - accuracy: 0.8165\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 696us/step - loss: 0.4258 - accuracy: 0.8135\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8150\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 703us/step - loss: 0.4218 - accuracy: 0.8165\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 670us/step - loss: 0.4212 - accuracy: 0.8185\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 692us/step - loss: 0.4196 - accuracy: 0.8210\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 689us/step - loss: 0.4178 - accuracy: 0.8155\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 692us/step - loss: 0.4171 - accuracy: 0.8200\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 734us/step - loss: 0.4156 - accuracy: 0.8215\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 704us/step - loss: 0.4144 - accuracy: 0.8190\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 699us/step - loss: 0.4142 - accuracy: 0.8185\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 693us/step - loss: 0.4122 - accuracy: 0.8215\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 690us/step - loss: 0.4120 - accuracy: 0.8185\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 707us/step - loss: 0.4108 - accuracy: 0.8225\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 722us/step - loss: 0.4112 - accuracy: 0.8215\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 831us/step - loss: 0.4088 - accuracy: 0.8205\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 722us/step - loss: 0.4073 - accuracy: 0.8225\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 679us/step - loss: 0.4070 - accuracy: 0.8240\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 674us/step - loss: 0.4053 - accuracy: 0.8225\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 714us/step - loss: 0.4039 - accuracy: 0.8230\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 722us/step - loss: 0.4039 - accuracy: 0.8240\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 707us/step - loss: 0.4046 - accuracy: 0.8215\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 680us/step - loss: 0.4009 - accuracy: 0.8250\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 700us/step - loss: 0.3993 - accuracy: 0.8265\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 778us/step - loss: 0.3978 - accuracy: 0.8270\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 752us/step - loss: 0.3963 - accuracy: 0.8260\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.3954 - accuracy: 0.8335\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8320\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8310\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 753us/step - loss: 0.3905 - accuracy: 0.8325\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 716us/step - loss: 0.3903 - accuracy: 0.8325\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 740us/step - loss: 0.3889 - accuracy: 0.8305\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 798us/step - loss: 0.3871 - accuracy: 0.8340\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 919us/step - loss: 0.3865 - accuracy: 0.8335\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 856us/step - loss: 0.3843 - accuracy: 0.8335\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 775us/step - loss: 0.3832 - accuracy: 0.8370\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 759us/step - loss: 0.3831 - accuracy: 0.8340\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 767us/step - loss: 0.3802 - accuracy: 0.8335\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 876us/step - loss: 0.3801 - accuracy: 0.8365\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 794us/step - loss: 0.3776 - accuracy: 0.8375\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 982us/step - loss: 0.3772 - accuracy: 0.8360\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 674us/step - loss: 0.3771 - accuracy: 0.8365\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 689us/step - loss: 0.3745 - accuracy: 0.8415\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 691us/step - loss: 0.3733 - accuracy: 0.8415\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8380\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 749us/step - loss: 0.3709 - accuracy: 0.8420\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 750us/step - loss: 0.3705 - accuracy: 0.8395\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 768us/step - loss: 0.3689 - accuracy: 0.8415\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 773us/step - loss: 0.3683 - accuracy: 0.8430\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 753us/step - loss: 0.3679 - accuracy: 0.8430\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 762us/step - loss: 0.3674 - accuracy: 0.8410\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 802us/step - loss: 0.3662 - accuracy: 0.8425\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8415\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 781us/step - loss: 0.3635 - accuracy: 0.8420\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 771us/step - loss: 0.3613 - accuracy: 0.8465\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 777us/step - loss: 0.3602 - accuracy: 0.8410\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 890us/step - loss: 0.3615 - accuracy: 0.8420\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 741us/step - loss: 0.3588 - accuracy: 0.8440\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 707us/step - loss: 0.3578 - accuracy: 0.8415\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 693us/step - loss: 0.3562 - accuracy: 0.8450\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.3548 - accuracy: 0.8445\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 721us/step - loss: 0.3544 - accuracy: 0.8435\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 700us/step - loss: 0.3533 - accuracy: 0.8420\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 688us/step - loss: 0.3530 - accuracy: 0.8455\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 695us/step - loss: 0.3519 - accuracy: 0.8465\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 711us/step - loss: 0.3514 - accuracy: 0.8465\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 698us/step - loss: 0.3486 - accuracy: 0.8505\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 675us/step - loss: 0.3528 - accuracy: 0.8460\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 970us/step - loss: 0.3492 - accuracy: 0.8490\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 840us/step - loss: 0.3473 - accuracy: 0.8480\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 694us/step - loss: 0.3467 - accuracy: 0.8490\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 714us/step - loss: 0.3452 - accuracy: 0.8475\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 705us/step - loss: 0.3443 - accuracy: 0.8505\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 717us/step - loss: 0.3449 - accuracy: 0.8495\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 671us/step - loss: 0.3440 - accuracy: 0.8490\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 702us/step - loss: 0.3441 - accuracy: 0.8525\n",
      "250/250 [==============================] - 0s 528us/step - loss: 0.3783 - accuracy: 0.8409\n",
      "250/250 [==============================] - 0s 431us/step\n",
      "[[6035  335]\n",
      " [ 938  692]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.90      6370\n",
      "           1       0.67      0.42      0.52      1630\n",
      "\n",
      "    accuracy                           0.84      8000\n",
      "   macro avg       0.77      0.69      0.71      8000\n",
      "weighted avg       0.83      0.84      0.83      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(X_train, X_test, y_train, y_test) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>0.220</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.476319</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457789</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8167</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.588634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607963</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>0.626</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.404408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217804</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.711785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9107</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8249</th>\n",
       "      <td>0.472</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8337</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.467497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470924</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.495535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "1344        0.220  0.297297     0.6  0.476319       0.333333          1   \n",
       "8167        0.726  0.081081     0.7  0.588634       0.000000          1   \n",
       "4747        0.626  0.621622     0.6  0.000000       0.333333          0   \n",
       "5004        0.304  0.527027     0.3  0.404408       0.000000          1   \n",
       "3124        0.820  0.283784     0.6  0.711785       0.000000          1   \n",
       "...           ...       ...     ...       ...            ...        ...   \n",
       "9107        0.610  0.270270     0.9  0.000000       0.000000          0   \n",
       "8249        0.472  0.270270     0.6  0.000000       0.333333          1   \n",
       "8337        0.368  0.310811     0.9  0.000000       0.333333          1   \n",
       "6279        0.814  0.500000     0.9  0.467497       1.000000          1   \n",
       "412         0.790  0.175676     0.3  0.495535       0.000000          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "1344               0         0.457789                  1                0   \n",
       "8167               1         0.607963                  1                0   \n",
       "4747               1         0.079332                  0                1   \n",
       "5004               0         0.217804                  1                0   \n",
       "3124               0         0.335631                  0                0   \n",
       "...              ...              ...                ...              ...   \n",
       "9107               1         0.452437                  0                1   \n",
       "8249               1         0.189639                  0                0   \n",
       "8337               0         0.069305                  0                0   \n",
       "6279               0         0.470924                  0                1   \n",
       "412                1         0.702267                  0                1   \n",
       "\n",
       "      Gender_Male  Exited  \n",
       "1344            0       1  \n",
       "8167            0       0  \n",
       "4747            1       0  \n",
       "5004            0       1  \n",
       "3124            1       1  \n",
       "...           ...     ...  \n",
       "9107            1       0  \n",
       "8249            0       0  \n",
       "8337            1       0  \n",
       "6279            0       1  \n",
       "412             0       0  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.concat([X_train, y_train], axis=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = new_df[new_df.Exited==0]\n",
    "df_1 = new_df[new_df.Exited==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, 407)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_0), len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>0.546</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.472181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>0.412</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.404</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133718</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>0.362</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.352033</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376222</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046</th>\n",
       "      <td>0.478</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.482639</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017592</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>0.168</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367787</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7223</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.616134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>0.720</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.373287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.467497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470924</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "9967        0.546  0.405405     0.5  0.472181       0.000000          1   \n",
       "6401        0.412  0.378378     1.0  0.000000       0.333333          0   \n",
       "919         0.404  0.364865     0.9  0.000000       0.333333          1   \n",
       "1226        0.362  0.324324     0.6  0.352033       0.333333          1   \n",
       "7046        0.478  0.027027     0.2  0.482639       0.333333          1   \n",
       "...           ...       ...     ...       ...            ...        ...   \n",
       "8379        0.168  0.500000     0.6  0.000000       0.000000          0   \n",
       "7223        0.898  0.175676     0.9  0.616134       0.000000          0   \n",
       "1046        0.914  0.324324     0.1  0.000000       0.000000          1   \n",
       "1487        0.720  0.445946     0.4  0.373287       0.000000          0   \n",
       "6279        0.814  0.500000     0.9  0.467497       1.000000          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "9967               1         0.792969                  0                0   \n",
       "6401               0         0.545915                  0                0   \n",
       "919                0         0.133718                  0                1   \n",
       "1226               0         0.376222                  1                0   \n",
       "7046               0         0.017592                  1                0   \n",
       "...              ...              ...                ...              ...   \n",
       "8379               1         0.367787                  0                1   \n",
       "7223               1         0.443009                  1                0   \n",
       "1046               0         0.082453                  0                1   \n",
       "1487               1         0.707012                  0                1   \n",
       "6279               0         0.470924                  0                1   \n",
       "\n",
       "      Gender_Male  Exited  \n",
       "9967            1       0  \n",
       "6401            0       0  \n",
       "919             1       0  \n",
       "1226            0       0  \n",
       "7046            0       0  \n",
       "...           ...     ...  \n",
       "8379            1       1  \n",
       "7223            1       1  \n",
       "1046            0       1  \n",
       "1487            0       1  \n",
       "6279            0       1  \n",
       "\n",
       "[814 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df_0.sample(407)\n",
    "df_undersampled = pd.concat([df_0, df_1], axis=0)\n",
    "df_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 923us/step - loss: 0.6938 - accuracy: 0.4939\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.6907 - accuracy: 0.5197\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 853us/step - loss: 0.6893 - accuracy: 0.5233\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 857us/step - loss: 0.6875 - accuracy: 0.5258\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 788us/step - loss: 0.6853 - accuracy: 0.5344\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 827us/step - loss: 0.6830 - accuracy: 0.5442\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 843us/step - loss: 0.6804 - accuracy: 0.5639\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 835us/step - loss: 0.6779 - accuracy: 0.5811\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 875us/step - loss: 0.6738 - accuracy: 0.5946\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 881us/step - loss: 0.6686 - accuracy: 0.6081\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 921us/step - loss: 0.6612 - accuracy: 0.6229\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6499\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 817us/step - loss: 0.6418 - accuracy: 0.6732\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 867us/step - loss: 0.6333 - accuracy: 0.6806\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 884us/step - loss: 0.6242 - accuracy: 0.6830\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 791us/step - loss: 0.6172 - accuracy: 0.6769\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 920us/step - loss: 0.6108 - accuracy: 0.6769\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 777us/step - loss: 0.6062 - accuracy: 0.6929\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 775us/step - loss: 0.6023 - accuracy: 0.6818\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 784us/step - loss: 0.5962 - accuracy: 0.6843\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 776us/step - loss: 0.5931 - accuracy: 0.6892\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 847us/step - loss: 0.5889 - accuracy: 0.6867\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 778us/step - loss: 0.5858 - accuracy: 0.6953\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 819us/step - loss: 0.5823 - accuracy: 0.6990\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 951us/step - loss: 0.5795 - accuracy: 0.6941\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 781us/step - loss: 0.5778 - accuracy: 0.7076\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 784us/step - loss: 0.5753 - accuracy: 0.7088\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 763us/step - loss: 0.5726 - accuracy: 0.7064\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 771us/step - loss: 0.5691 - accuracy: 0.7101\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 818us/step - loss: 0.5674 - accuracy: 0.7224\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 790us/step - loss: 0.5647 - accuracy: 0.7174\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 805us/step - loss: 0.5629 - accuracy: 0.7248\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7236\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7297\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 865us/step - loss: 0.5574 - accuracy: 0.7310\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 797us/step - loss: 0.5532 - accuracy: 0.7285\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 938us/step - loss: 0.5509 - accuracy: 0.7322\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 784us/step - loss: 0.5491 - accuracy: 0.7359\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 765us/step - loss: 0.5467 - accuracy: 0.7396\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 844us/step - loss: 0.5459 - accuracy: 0.7285\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 760us/step - loss: 0.5426 - accuracy: 0.7346\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 790us/step - loss: 0.5414 - accuracy: 0.7371\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 822us/step - loss: 0.5393 - accuracy: 0.7371\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 766us/step - loss: 0.5368 - accuracy: 0.7420\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 808us/step - loss: 0.5349 - accuracy: 0.7359\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 861us/step - loss: 0.5326 - accuracy: 0.7408\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 806us/step - loss: 0.5306 - accuracy: 0.7494\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 839us/step - loss: 0.5288 - accuracy: 0.7531\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 791us/step - loss: 0.5270 - accuracy: 0.7469\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 792us/step - loss: 0.5259 - accuracy: 0.7518\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 856us/step - loss: 0.5242 - accuracy: 0.7494\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 824us/step - loss: 0.5229 - accuracy: 0.7408\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 872us/step - loss: 0.5235 - accuracy: 0.7482\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 812us/step - loss: 0.5211 - accuracy: 0.7396\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 818us/step - loss: 0.5178 - accuracy: 0.7518\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 837us/step - loss: 0.5172 - accuracy: 0.7469\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 806us/step - loss: 0.5170 - accuracy: 0.7469\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 859us/step - loss: 0.5157 - accuracy: 0.7432\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 756us/step - loss: 0.5136 - accuracy: 0.7531\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 783us/step - loss: 0.5122 - accuracy: 0.7469\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5103 - accuracy: 0.7580\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 765us/step - loss: 0.5096 - accuracy: 0.7531\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 803us/step - loss: 0.5079 - accuracy: 0.7568\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 823us/step - loss: 0.5072 - accuracy: 0.7641\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 830us/step - loss: 0.5072 - accuracy: 0.7592\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 802us/step - loss: 0.5057 - accuracy: 0.7617\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7543\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 839us/step - loss: 0.5031 - accuracy: 0.7592\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 790us/step - loss: 0.5019 - accuracy: 0.7641\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 860us/step - loss: 0.5043 - accuracy: 0.7617\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 809us/step - loss: 0.5013 - accuracy: 0.7641\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 779us/step - loss: 0.4988 - accuracy: 0.7678\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 886us/step - loss: 0.5000 - accuracy: 0.7666\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 777us/step - loss: 0.5006 - accuracy: 0.7555\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 862us/step - loss: 0.4971 - accuracy: 0.7617\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 793us/step - loss: 0.4964 - accuracy: 0.7654\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 829us/step - loss: 0.4947 - accuracy: 0.7604\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 796us/step - loss: 0.4936 - accuracy: 0.7654\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 772us/step - loss: 0.4932 - accuracy: 0.7617\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 854us/step - loss: 0.4927 - accuracy: 0.7604\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 780us/step - loss: 0.4915 - accuracy: 0.7629\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 766us/step - loss: 0.4921 - accuracy: 0.7654\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 832us/step - loss: 0.4894 - accuracy: 0.7629\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 785us/step - loss: 0.4901 - accuracy: 0.7654\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 871us/step - loss: 0.4897 - accuracy: 0.7629\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 845us/step - loss: 0.4886 - accuracy: 0.7654\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 805us/step - loss: 0.4877 - accuracy: 0.7666\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 774us/step - loss: 0.4873 - accuracy: 0.7690\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 792us/step - loss: 0.4868 - accuracy: 0.7703\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 931us/step - loss: 0.4859 - accuracy: 0.7654\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 787us/step - loss: 0.4856 - accuracy: 0.7654\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 792us/step - loss: 0.4852 - accuracy: 0.7715\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7703\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 851us/step - loss: 0.4858 - accuracy: 0.7592\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 787us/step - loss: 0.4842 - accuracy: 0.7678\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 782us/step - loss: 0.4835 - accuracy: 0.7690\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 919us/step - loss: 0.4831 - accuracy: 0.7641\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 811us/step - loss: 0.4827 - accuracy: 0.7666\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 872us/step - loss: 0.4829 - accuracy: 0.7568\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 775us/step - loss: 0.4810 - accuracy: 0.7678\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.5140 - accuracy: 0.7439\n",
      "250/250 [==============================] - 0s 432us/step\n",
      "[[4728 1642]\n",
      " [ 407 1223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82      6370\n",
      "           1       0.43      0.75      0.54      1630\n",
      "\n",
      "    accuracy                           0.74      8000\n",
      "   macro avg       0.67      0.75      0.68      8000\n",
      "weighted avg       0.82      0.74      0.77      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_undersampled.drop(\"Exited\", axis=1)\n",
    "y = df_undersampled[\"Exited\"]\n",
    "ANN(X, X_test,y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = new_df[new_df.Exited==0]\n",
    "df_1 = new_df[new_df.Exited==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, 407)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_0), len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.sample(1593, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, 1593)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_0), len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8167</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.588634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607963</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>0.626</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>0.634</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.344344</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>0.416</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443858</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986358</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.351302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548290</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073348</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.541425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.467497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470924</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.658722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070498</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9747</th>\n",
       "      <td>0.520</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.342921</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.963749</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3186 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "8167        0.726  0.081081     0.7  0.588634       0.000000          1   \n",
       "4747        0.626  0.621622     0.6  0.000000       0.333333          0   \n",
       "2090        0.634  0.283784     0.9  0.000000       0.333333          1   \n",
       "3298        0.416  0.094595     1.0  0.443858       0.333333          1   \n",
       "9485        1.000  0.256757     0.4  0.351302       0.000000          1   \n",
       "...           ...       ...     ...       ...            ...        ...   \n",
       "805         0.880  0.378378     0.9  0.000000       0.000000          0   \n",
       "399         0.532  0.648649     0.1  0.541425       0.000000          1   \n",
       "6279        0.814  0.500000     0.9  0.467497       1.000000          1   \n",
       "338         0.910  0.283784     0.5  0.658722       0.000000          1   \n",
       "9747        0.520  0.689189     0.5  0.342921       0.666667          0   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "8167               1         0.607963                  1                0   \n",
       "4747               1         0.079332                  0                1   \n",
       "2090               0         0.344344                  0                1   \n",
       "3298               0         0.986358                  1                0   \n",
       "9485               0         0.548290                  0                1   \n",
       "...              ...              ...                ...              ...   \n",
       "805                0         0.073348                  0                1   \n",
       "399                0         0.919232                  0                0   \n",
       "6279               0         0.470924                  0                1   \n",
       "338                0         0.070498                  0                1   \n",
       "9747               0         0.963749                  1                0   \n",
       "\n",
       "      Gender_Male  Exited  \n",
       "8167            0       0  \n",
       "4747            1       0  \n",
       "2090            1       0  \n",
       "3298            1       0  \n",
       "9485            1       0  \n",
       "...           ...     ...  \n",
       "805             0       1  \n",
       "399             0       1  \n",
       "6279            0       1  \n",
       "338             0       1  \n",
       "9747            0       1  \n",
       "\n",
       "[3186 rows x 12 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oversampled = pd.concat([df_0, df_1])\n",
    "df_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 766us/step - loss: 0.6752 - accuracy: 0.5876\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 703us/step - loss: 0.6542 - accuracy: 0.6337\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 729us/step - loss: 0.6373 - accuracy: 0.6416\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 726us/step - loss: 0.6255 - accuracy: 0.6441\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 774us/step - loss: 0.6179 - accuracy: 0.6513\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.6610\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 729us/step - loss: 0.6053 - accuracy: 0.6704\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 742us/step - loss: 0.5992 - accuracy: 0.6742\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 708us/step - loss: 0.5935 - accuracy: 0.6868\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 709us/step - loss: 0.5869 - accuracy: 0.6911\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 765us/step - loss: 0.5808 - accuracy: 0.6974\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 746us/step - loss: 0.5754 - accuracy: 0.6962\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 764us/step - loss: 0.5693 - accuracy: 0.6999\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.5628 - accuracy: 0.7059\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 749us/step - loss: 0.5576 - accuracy: 0.7094\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 735us/step - loss: 0.5523 - accuracy: 0.7090\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 734us/step - loss: 0.5466 - accuracy: 0.7134\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 713us/step - loss: 0.5403 - accuracy: 0.7216\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 718us/step - loss: 0.5347 - accuracy: 0.7307\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 719us/step - loss: 0.5305 - accuracy: 0.7329\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 712us/step - loss: 0.5253 - accuracy: 0.7417\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 718us/step - loss: 0.5216 - accuracy: 0.7454\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 686us/step - loss: 0.5164 - accuracy: 0.7539\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 676us/step - loss: 0.5120 - accuracy: 0.7542\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 966us/step - loss: 0.5077 - accuracy: 0.7549\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 729us/step - loss: 0.5043 - accuracy: 0.7552\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 696us/step - loss: 0.4993 - accuracy: 0.7589\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 713us/step - loss: 0.4952 - accuracy: 0.7690\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 708us/step - loss: 0.4934 - accuracy: 0.7693\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 685us/step - loss: 0.4891 - accuracy: 0.7668\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 678us/step - loss: 0.4872 - accuracy: 0.7746\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 679us/step - loss: 0.4834 - accuracy: 0.7721\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 711us/step - loss: 0.4809 - accuracy: 0.7750\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 690us/step - loss: 0.4782 - accuracy: 0.7762\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 704us/step - loss: 0.4759 - accuracy: 0.7743\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 719us/step - loss: 0.4731 - accuracy: 0.7768\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 686us/step - loss: 0.4718 - accuracy: 0.7787\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 684us/step - loss: 0.4687 - accuracy: 0.7787\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 756us/step - loss: 0.4666 - accuracy: 0.7781\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 699us/step - loss: 0.4655 - accuracy: 0.7809\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 691us/step - loss: 0.4650 - accuracy: 0.7812\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7806\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 682us/step - loss: 0.4599 - accuracy: 0.7778\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 679us/step - loss: 0.4569 - accuracy: 0.7806\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 710us/step - loss: 0.4569 - accuracy: 0.7834\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 699us/step - loss: 0.4545 - accuracy: 0.7856\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 708us/step - loss: 0.4525 - accuracy: 0.7884\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 719us/step - loss: 0.4536 - accuracy: 0.7831\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 690us/step - loss: 0.4502 - accuracy: 0.7856\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 704us/step - loss: 0.4476 - accuracy: 0.7866\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 694us/step - loss: 0.4478 - accuracy: 0.7881\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 682us/step - loss: 0.4464 - accuracy: 0.7913\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 752us/step - loss: 0.4459 - accuracy: 0.7900\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 717us/step - loss: 0.4430 - accuracy: 0.7941\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 679us/step - loss: 0.4426 - accuracy: 0.7944\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 689us/step - loss: 0.4407 - accuracy: 0.7919\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 690us/step - loss: 0.4409 - accuracy: 0.7922\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 697us/step - loss: 0.4392 - accuracy: 0.7950\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 978us/step - loss: 0.4376 - accuracy: 0.7988\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 688us/step - loss: 0.4373 - accuracy: 0.7928\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 684us/step - loss: 0.4359 - accuracy: 0.7963\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 691us/step - loss: 0.4361 - accuracy: 0.7950\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 688us/step - loss: 0.4364 - accuracy: 0.7954\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 674us/step - loss: 0.4336 - accuracy: 0.7982\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 690us/step - loss: 0.4343 - accuracy: 0.7982\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 677us/step - loss: 0.4328 - accuracy: 0.7966\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 664us/step - loss: 0.4323 - accuracy: 0.8023\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 727us/step - loss: 0.4308 - accuracy: 0.8038\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 687us/step - loss: 0.4306 - accuracy: 0.8013\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 675us/step - loss: 0.4297 - accuracy: 0.8023\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 693us/step - loss: 0.4287 - accuracy: 0.7969\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 678us/step - loss: 0.4279 - accuracy: 0.8016\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 697us/step - loss: 0.4277 - accuracy: 0.8026\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 702us/step - loss: 0.4266 - accuracy: 0.7966\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 708us/step - loss: 0.4261 - accuracy: 0.8048\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 705us/step - loss: 0.4253 - accuracy: 0.8048\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 717us/step - loss: 0.4257 - accuracy: 0.8035\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 989us/step - loss: 0.4239 - accuracy: 0.8032\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 701us/step - loss: 0.4235 - accuracy: 0.8060\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 696us/step - loss: 0.4217 - accuracy: 0.8057\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 778us/step - loss: 0.4230 - accuracy: 0.8048\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 693us/step - loss: 0.4207 - accuracy: 0.8082\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 696us/step - loss: 0.4203 - accuracy: 0.8041\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 695us/step - loss: 0.4193 - accuracy: 0.8089\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 705us/step - loss: 0.4187 - accuracy: 0.8048\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 959us/step - loss: 0.4195 - accuracy: 0.8048\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 681us/step - loss: 0.4178 - accuracy: 0.8110\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 666us/step - loss: 0.4180 - accuracy: 0.8048\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 699us/step - loss: 0.4158 - accuracy: 0.8092\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 669us/step - loss: 0.4169 - accuracy: 0.8001\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 682us/step - loss: 0.4154 - accuracy: 0.8054\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 684us/step - loss: 0.4144 - accuracy: 0.8089\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 672us/step - loss: 0.4139 - accuracy: 0.8032\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.4133 - accuracy: 0.8073\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 846us/step - loss: 0.4119 - accuracy: 0.8076\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 982us/step - loss: 0.4133 - accuracy: 0.8023\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 667us/step - loss: 0.4108 - accuracy: 0.8126\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.4098 - accuracy: 0.8054\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 677us/step - loss: 0.4094 - accuracy: 0.8057\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 679us/step - loss: 0.4102 - accuracy: 0.8057\n",
      "250/250 [==============================] - 0s 500us/step - loss: 0.5076 - accuracy: 0.7539\n",
      "250/250 [==============================] - 0s 436us/step\n",
      "[[4855 1515]\n",
      " [ 454 1176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83      6370\n",
      "           1       0.44      0.72      0.54      1630\n",
      "\n",
      "    accuracy                           0.75      8000\n",
      "   macro avg       0.68      0.74      0.69      8000\n",
      "weighted avg       0.82      0.75      0.77      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_oversampled.drop(\"Exited\", axis=1)\n",
    "y = df_oversampled[\"Exited\"]\n",
    "ANN(X, X_test,y, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 773us/step - loss: 0.6666 - accuracy: 0.5932\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 705us/step - loss: 0.6441 - accuracy: 0.6318\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 714us/step - loss: 0.6302 - accuracy: 0.6516\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 719us/step - loss: 0.6180 - accuracy: 0.6692\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 708us/step - loss: 0.6067 - accuracy: 0.6858\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 713us/step - loss: 0.5977 - accuracy: 0.6955\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.5882 - accuracy: 0.7034\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 736us/step - loss: 0.5796 - accuracy: 0.7056\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 723us/step - loss: 0.5723 - accuracy: 0.7131\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 777us/step - loss: 0.5651 - accuracy: 0.7178\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7235\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 692us/step - loss: 0.5531 - accuracy: 0.7241\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 747us/step - loss: 0.5480 - accuracy: 0.7254\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 712us/step - loss: 0.5433 - accuracy: 0.7279\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 731us/step - loss: 0.5396 - accuracy: 0.7316\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 709us/step - loss: 0.5354 - accuracy: 0.7338\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 707us/step - loss: 0.5338 - accuracy: 0.7376\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 684us/step - loss: 0.5306 - accuracy: 0.7351\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 756us/step - loss: 0.5273 - accuracy: 0.7420\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 712us/step - loss: 0.5243 - accuracy: 0.7404\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 713us/step - loss: 0.5250 - accuracy: 0.7401\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 689us/step - loss: 0.5187 - accuracy: 0.7448\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.5172 - accuracy: 0.7426\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 682us/step - loss: 0.5156 - accuracy: 0.7414\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 716us/step - loss: 0.5134 - accuracy: 0.7417\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 724us/step - loss: 0.5138 - accuracy: 0.7420\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 704us/step - loss: 0.5095 - accuracy: 0.7476\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 698us/step - loss: 0.5096 - accuracy: 0.7480\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 683us/step - loss: 0.5077 - accuracy: 0.7470\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 692us/step - loss: 0.5064 - accuracy: 0.7461\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 686us/step - loss: 0.5035 - accuracy: 0.7524\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 693us/step - loss: 0.5036 - accuracy: 0.7514\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7524\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 737us/step - loss: 0.4986 - accuracy: 0.7542\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 725us/step - loss: 0.4994 - accuracy: 0.7539\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 728us/step - loss: 0.4975 - accuracy: 0.7511\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 712us/step - loss: 0.4973 - accuracy: 0.7524\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 701us/step - loss: 0.4965 - accuracy: 0.7524\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 688us/step - loss: 0.4942 - accuracy: 0.7567\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 685us/step - loss: 0.4929 - accuracy: 0.7533\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 778us/step - loss: 0.4934 - accuracy: 0.7580\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 802us/step - loss: 0.4912 - accuracy: 0.7580\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 787us/step - loss: 0.4903 - accuracy: 0.7615\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 721us/step - loss: 0.4897 - accuracy: 0.7583\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 867us/step - loss: 0.4882 - accuracy: 0.7633\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 849us/step - loss: 0.4869 - accuracy: 0.7596\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.4880 - accuracy: 0.7593\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7637\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 735us/step - loss: 0.4835 - accuracy: 0.7643\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 725us/step - loss: 0.4835 - accuracy: 0.7662\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 714us/step - loss: 0.4833 - accuracy: 0.7615\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 706us/step - loss: 0.4829 - accuracy: 0.7630\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 708us/step - loss: 0.4813 - accuracy: 0.7662\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 722us/step - loss: 0.4807 - accuracy: 0.7680\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 774us/step - loss: 0.4799 - accuracy: 0.7687\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 721us/step - loss: 0.4807 - accuracy: 0.7640\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 705us/step - loss: 0.4779 - accuracy: 0.7687\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 697us/step - loss: 0.4761 - accuracy: 0.7659\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 726us/step - loss: 0.4760 - accuracy: 0.7680\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 724us/step - loss: 0.4759 - accuracy: 0.7715\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 787us/step - loss: 0.4759 - accuracy: 0.7662\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 686us/step - loss: 0.4735 - accuracy: 0.7718\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.4731 - accuracy: 0.7659\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 684us/step - loss: 0.4719 - accuracy: 0.7702\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 675us/step - loss: 0.4722 - accuracy: 0.7702\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 675us/step - loss: 0.4717 - accuracy: 0.7696\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 974us/step - loss: 0.4712 - accuracy: 0.7721\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 678us/step - loss: 0.4712 - accuracy: 0.7724\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 682us/step - loss: 0.4705 - accuracy: 0.7699\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 677us/step - loss: 0.4688 - accuracy: 0.7709\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 675us/step - loss: 0.4695 - accuracy: 0.7696\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 699us/step - loss: 0.4666 - accuracy: 0.7712\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 683us/step - loss: 0.4687 - accuracy: 0.7690\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 704us/step - loss: 0.4675 - accuracy: 0.7731\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 671us/step - loss: 0.4652 - accuracy: 0.7746\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 751us/step - loss: 0.4654 - accuracy: 0.7718\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 667us/step - loss: 0.4652 - accuracy: 0.7734\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 697us/step - loss: 0.4631 - accuracy: 0.7715\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 674us/step - loss: 0.4652 - accuracy: 0.7693\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.4629 - accuracy: 0.7718\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 671us/step - loss: 0.4633 - accuracy: 0.7731\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 691us/step - loss: 0.4624 - accuracy: 0.7724\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 671us/step - loss: 0.4608 - accuracy: 0.7728\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 962us/step - loss: 0.4606 - accuracy: 0.7712\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 684us/step - loss: 0.4609 - accuracy: 0.7728\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 684us/step - loss: 0.4600 - accuracy: 0.7702\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 683us/step - loss: 0.4586 - accuracy: 0.7712\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 672us/step - loss: 0.4578 - accuracy: 0.7746\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 685us/step - loss: 0.4566 - accuracy: 0.7731\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 688us/step - loss: 0.4584 - accuracy: 0.7753\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 679us/step - loss: 0.4553 - accuracy: 0.7743\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 748us/step - loss: 0.4555 - accuracy: 0.7743\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.4541 - accuracy: 0.7756\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 676us/step - loss: 0.4545 - accuracy: 0.7728\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 672us/step - loss: 0.4533 - accuracy: 0.7756\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 681us/step - loss: 0.4535 - accuracy: 0.7759\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 689us/step - loss: 0.4529 - accuracy: 0.7775\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 679us/step - loss: 0.4518 - accuracy: 0.7743\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 676us/step - loss: 0.4514 - accuracy: 0.7775\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 669us/step - loss: 0.4503 - accuracy: 0.7778\n",
      "250/250 [==============================] - 0s 508us/step - loss: 0.5263 - accuracy: 0.7523\n",
      "250/250 [==============================] - 0s 445us/step\n",
      "[[4937 1433]\n",
      " [ 549 1081]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.83      6370\n",
      "           1       0.43      0.66      0.52      1630\n",
      "\n",
      "    accuracy                           0.75      8000\n",
      "   macro avg       0.66      0.72      0.68      8000\n",
      "weighted avg       0.80      0.75      0.77      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ANN(X_sm, X_test,y_sm, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, 407)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = new_df[new_df.Exited==0]\n",
    "df_1 = new_df[new_df.Exited==1]\n",
    "len(df_0), len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1593//407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ensemble = []\n",
    "for i in range(3):\n",
    "    df_ensemble = pd.concat([df_0.sample(407), df_1])\n",
    "    lst_ensemble.append(df_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.740198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.512504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.976</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.490661</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728841</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>0.668</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.534787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887560</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>0.482</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>0.282</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.363834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>0.168</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367787</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7223</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.616134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>0.720</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.373287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.467497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470924</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "7637        0.832  0.189189     0.6  0.740198       0.000000          1   \n",
       "994         0.976  0.337838     0.9  0.490661       0.333333          1   \n",
       "5286        0.668  0.310811     0.1  0.534787       0.000000          0   \n",
       "1357        0.482  0.337838     0.3  0.000000       0.333333          0   \n",
       "7302        0.282  0.729730     0.6  0.363834       0.000000          1   \n",
       "...           ...       ...     ...       ...            ...        ...   \n",
       "8379        0.168  0.500000     0.6  0.000000       0.000000          0   \n",
       "7223        0.898  0.175676     0.9  0.616134       0.000000          0   \n",
       "1046        0.914  0.324324     0.1  0.000000       0.000000          1   \n",
       "1487        0.720  0.445946     0.4  0.373287       0.000000          0   \n",
       "6279        0.814  0.500000     0.9  0.467497       1.000000          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "7637               1         0.512504                  0                0   \n",
       "994                0         0.728841                  0                1   \n",
       "5286               0         0.887560                  0                1   \n",
       "1357               1         0.994669                  0                0   \n",
       "7302               1         0.035110                  0                0   \n",
       "...              ...              ...                ...              ...   \n",
       "8379               1         0.367787                  0                1   \n",
       "7223               1         0.443009                  1                0   \n",
       "1046               0         0.082453                  0                1   \n",
       "1487               1         0.707012                  0                1   \n",
       "6279               0         0.470924                  0                1   \n",
       "\n",
       "      Gender_Male  Exited  \n",
       "7637            1       0  \n",
       "994             1       0  \n",
       "5286            0       0  \n",
       "1357            1       0  \n",
       "7302            0       0  \n",
       "...           ...     ...  \n",
       "8379            1       1  \n",
       "7223            1       1  \n",
       "1046            0       1  \n",
       "1487            0       1  \n",
       "6279            0       1  \n",
       "\n",
       "[814 rows x 12 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_ensemble[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 861us/step - loss: 0.6962 - accuracy: 0.4103\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 761us/step - loss: 0.6940 - accuracy: 0.4447\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 744us/step - loss: 0.6935 - accuracy: 0.4582\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 738us/step - loss: 0.6933 - accuracy: 0.4717\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 687us/step - loss: 0.6931 - accuracy: 0.4840\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5123\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5025\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 794us/step - loss: 0.6925 - accuracy: 0.5049\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 733us/step - loss: 0.6918 - accuracy: 0.5270\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 762us/step - loss: 0.6905 - accuracy: 0.5295\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 741us/step - loss: 0.6881 - accuracy: 0.5516\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.6834 - accuracy: 0.5725\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 749us/step - loss: 0.6766 - accuracy: 0.5921\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 735us/step - loss: 0.6646 - accuracy: 0.6265\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 736us/step - loss: 0.6494 - accuracy: 0.6450\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.6364 - accuracy: 0.6425\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 717us/step - loss: 0.6274 - accuracy: 0.6450\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 727us/step - loss: 0.6189 - accuracy: 0.6474\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.6125 - accuracy: 0.6474\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 737us/step - loss: 0.6075 - accuracy: 0.6572\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 735us/step - loss: 0.6025 - accuracy: 0.6658\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 723us/step - loss: 0.5981 - accuracy: 0.6671\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5940 - accuracy: 0.6757\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 733us/step - loss: 0.5904 - accuracy: 0.6781\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 821us/step - loss: 0.5877 - accuracy: 0.6794\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 745us/step - loss: 0.5868 - accuracy: 0.6769\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 721us/step - loss: 0.5838 - accuracy: 0.6990\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 738us/step - loss: 0.5806 - accuracy: 0.6855\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 721us/step - loss: 0.5772 - accuracy: 0.7002\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 743us/step - loss: 0.5747 - accuracy: 0.7002\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.5739 - accuracy: 0.7027\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 747us/step - loss: 0.5722 - accuracy: 0.7064\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 735us/step - loss: 0.5692 - accuracy: 0.7113\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 731us/step - loss: 0.5680 - accuracy: 0.7027\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 716us/step - loss: 0.5653 - accuracy: 0.7113\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 737us/step - loss: 0.5655 - accuracy: 0.7150\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 730us/step - loss: 0.5643 - accuracy: 0.7211\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.5617 - accuracy: 0.7076\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 712us/step - loss: 0.5595 - accuracy: 0.7285\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 716us/step - loss: 0.5579 - accuracy: 0.7125\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.7187\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7187\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 744us/step - loss: 0.5536 - accuracy: 0.7211\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.5528 - accuracy: 0.7224\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 768us/step - loss: 0.5519 - accuracy: 0.7297\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.5508 - accuracy: 0.7236\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 701us/step - loss: 0.5479 - accuracy: 0.7224\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 685us/step - loss: 0.5481 - accuracy: 0.7248\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5489 - accuracy: 0.7236\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 682us/step - loss: 0.5453 - accuracy: 0.7273\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 693us/step - loss: 0.5433 - accuracy: 0.7273\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 689us/step - loss: 0.5442 - accuracy: 0.7273\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 685us/step - loss: 0.5423 - accuracy: 0.7334\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 686us/step - loss: 0.5403 - accuracy: 0.7310\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 693us/step - loss: 0.5380 - accuracy: 0.7383\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.5367 - accuracy: 0.7371\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 709us/step - loss: 0.5365 - accuracy: 0.7383\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 713us/step - loss: 0.5350 - accuracy: 0.7420\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 727us/step - loss: 0.5338 - accuracy: 0.7408\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 786us/step - loss: 0.5334 - accuracy: 0.7383\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 736us/step - loss: 0.5315 - accuracy: 0.7420\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 690us/step - loss: 0.5311 - accuracy: 0.7408\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.5324 - accuracy: 0.7432\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 699us/step - loss: 0.5291 - accuracy: 0.7383\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 692us/step - loss: 0.5273 - accuracy: 0.7482\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 692us/step - loss: 0.5268 - accuracy: 0.7420\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 683us/step - loss: 0.5256 - accuracy: 0.7494\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 686us/step - loss: 0.5260 - accuracy: 0.7445\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7420\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 987us/step - loss: 0.5222 - accuracy: 0.7506\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 743us/step - loss: 0.5212 - accuracy: 0.7506\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 712us/step - loss: 0.5205 - accuracy: 0.7469\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.5216 - accuracy: 0.7420\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 746us/step - loss: 0.5193 - accuracy: 0.7482\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 726us/step - loss: 0.5179 - accuracy: 0.7482\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 720us/step - loss: 0.5173 - accuracy: 0.7457\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 729us/step - loss: 0.5160 - accuracy: 0.7469\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.5148 - accuracy: 0.7482\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.5145 - accuracy: 0.7482\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 719us/step - loss: 0.5147 - accuracy: 0.7482\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.5124 - accuracy: 0.7506\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 723us/step - loss: 0.5115 - accuracy: 0.7506\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 698us/step - loss: 0.5103 - accuracy: 0.7543\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.5103 - accuracy: 0.7494\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 687us/step - loss: 0.5092 - accuracy: 0.7543\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 693us/step - loss: 0.5084 - accuracy: 0.7543\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 759us/step - loss: 0.5078 - accuracy: 0.7494\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 829us/step - loss: 0.5085 - accuracy: 0.7568\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 805us/step - loss: 0.5050 - accuracy: 0.7494\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7506\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.5046 - accuracy: 0.7580\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7482\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7457\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 721us/step - loss: 0.5011 - accuracy: 0.7555\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 976us/step - loss: 0.5003 - accuracy: 0.7604\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7518\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 766us/step - loss: 0.4989 - accuracy: 0.7531\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 691us/step - loss: 0.4993 - accuracy: 0.7543\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.4968 - accuracy: 0.7555\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 681us/step - loss: 0.4964 - accuracy: 0.7543\n",
      "250/250 [==============================] - 0s 494us/step - loss: 0.5589 - accuracy: 0.7246\n",
      "250/250 [==============================] - 0s 401us/step\n",
      "[[4604 1766]\n",
      " [ 437 1193]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.81      6370\n",
      "           1       0.40      0.73      0.52      1630\n",
      "\n",
      "    accuracy                           0.72      8000\n",
      "   macro avg       0.66      0.73      0.66      8000\n",
      "weighted avg       0.81      0.72      0.75      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = lst_ensemble[0].drop(\"Exited\", axis=1)\n",
    "y = lst_ensemble[0][\"Exited\"]\n",
    "y_pred1= ANN(X, X_test,y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 884us/step - loss: 0.6659 - accuracy: 0.6069\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 776us/step - loss: 0.6569 - accuracy: 0.6130\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 744us/step - loss: 0.6505 - accuracy: 0.6179\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 725us/step - loss: 0.6469 - accuracy: 0.6216\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 698us/step - loss: 0.6418 - accuracy: 0.6388\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 724us/step - loss: 0.6391 - accuracy: 0.6376\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 724us/step - loss: 0.6348 - accuracy: 0.6474\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 705us/step - loss: 0.6320 - accuracy: 0.6572\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 725us/step - loss: 0.6287 - accuracy: 0.6585\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 705us/step - loss: 0.6265 - accuracy: 0.6646\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 735us/step - loss: 0.6247 - accuracy: 0.6658\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 727us/step - loss: 0.6228 - accuracy: 0.6622\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.6202 - accuracy: 0.6683\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 722us/step - loss: 0.6179 - accuracy: 0.6695\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 755us/step - loss: 0.6152 - accuracy: 0.6757\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 717us/step - loss: 0.6138 - accuracy: 0.6720\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 736us/step - loss: 0.6113 - accuracy: 0.6769\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 734us/step - loss: 0.6098 - accuracy: 0.6769\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 744us/step - loss: 0.6067 - accuracy: 0.6769\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 714us/step - loss: 0.6053 - accuracy: 0.6794\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.6033 - accuracy: 0.6830\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.6033 - accuracy: 0.6794\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 713us/step - loss: 0.6026 - accuracy: 0.6830\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 721us/step - loss: 0.5988 - accuracy: 0.6794\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 690us/step - loss: 0.5966 - accuracy: 0.6892\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 696us/step - loss: 0.5951 - accuracy: 0.6892\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 701us/step - loss: 0.5936 - accuracy: 0.6867\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.5929 - accuracy: 0.6818\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 750us/step - loss: 0.5907 - accuracy: 0.6880\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6781\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.6855\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 734us/step - loss: 0.5870 - accuracy: 0.6855\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.5851 - accuracy: 0.6769\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 709us/step - loss: 0.5844 - accuracy: 0.6818\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.5840 - accuracy: 0.6855\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5829 - accuracy: 0.6818\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5805 - accuracy: 0.6867\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 719us/step - loss: 0.5803 - accuracy: 0.6867\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.5794 - accuracy: 0.6867\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.5786 - accuracy: 0.6904\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 700us/step - loss: 0.5770 - accuracy: 0.6916\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5775 - accuracy: 0.6855\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 685us/step - loss: 0.5754 - accuracy: 0.6880\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 692us/step - loss: 0.5741 - accuracy: 0.6904\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 706us/step - loss: 0.5729 - accuracy: 0.6941\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 724us/step - loss: 0.5718 - accuracy: 0.6916\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.5708 - accuracy: 0.6916\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 714us/step - loss: 0.5697 - accuracy: 0.6953\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 727us/step - loss: 0.5691 - accuracy: 0.6892\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 689us/step - loss: 0.5679 - accuracy: 0.6830\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 727us/step - loss: 0.5675 - accuracy: 0.6978\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 692us/step - loss: 0.5671 - accuracy: 0.6892\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 696us/step - loss: 0.5661 - accuracy: 0.6941\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.5652 - accuracy: 0.6953\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.5637 - accuracy: 0.6966\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 709us/step - loss: 0.5617 - accuracy: 0.6929\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 683us/step - loss: 0.5626 - accuracy: 0.6941\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5625 - accuracy: 0.7039\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 704us/step - loss: 0.5586 - accuracy: 0.7027\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5565 - accuracy: 0.6990\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 959us/step - loss: 0.5568 - accuracy: 0.7002\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.6978\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 756us/step - loss: 0.5523 - accuracy: 0.7015\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.5502 - accuracy: 0.7052\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 719us/step - loss: 0.5450 - accuracy: 0.7224\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 698us/step - loss: 0.5440 - accuracy: 0.7002\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5434 - accuracy: 0.7076\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5365 - accuracy: 0.7199\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 732us/step - loss: 0.5340 - accuracy: 0.7150\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.5304 - accuracy: 0.7211\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 691us/step - loss: 0.5300 - accuracy: 0.7150\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 687us/step - loss: 0.5253 - accuracy: 0.7224\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 682us/step - loss: 0.5236 - accuracy: 0.7273\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 683us/step - loss: 0.5202 - accuracy: 0.7248\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 723us/step - loss: 0.5194 - accuracy: 0.7285\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5176 - accuracy: 0.7248\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 714us/step - loss: 0.5139 - accuracy: 0.7297\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5125 - accuracy: 0.7346\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 699us/step - loss: 0.5115 - accuracy: 0.7297\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.5079 - accuracy: 0.7445\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 693us/step - loss: 0.5067 - accuracy: 0.7322\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 717us/step - loss: 0.5052 - accuracy: 0.7383\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.5036 - accuracy: 0.7371\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 754us/step - loss: 0.5018 - accuracy: 0.7469\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 704us/step - loss: 0.5037 - accuracy: 0.7494\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 692us/step - loss: 0.4978 - accuracy: 0.7420\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.4978 - accuracy: 0.7396\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 942us/step - loss: 0.4937 - accuracy: 0.7457\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7531\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 745us/step - loss: 0.4932 - accuracy: 0.7555\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 673us/step - loss: 0.4910 - accuracy: 0.7432\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 712us/step - loss: 0.4896 - accuracy: 0.7543\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.4897 - accuracy: 0.7482\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.4887 - accuracy: 0.7604\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 688us/step - loss: 0.4853 - accuracy: 0.7506\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 698us/step - loss: 0.4894 - accuracy: 0.7580\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 682us/step - loss: 0.4834 - accuracy: 0.7617\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 706us/step - loss: 0.4873 - accuracy: 0.7580\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7518\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 993us/step - loss: 0.4820 - accuracy: 0.7604\n",
      "250/250 [==============================] - 0s 572us/step - loss: 0.4916 - accuracy: 0.7830\n",
      "250/250 [==============================] - 0s 444us/step\n",
      "[[5167 1203]\n",
      " [ 533 1097]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86      6370\n",
      "           1       0.48      0.67      0.56      1630\n",
      "\n",
      "    accuracy                           0.78      8000\n",
      "   macro avg       0.69      0.74      0.71      8000\n",
      "weighted avg       0.82      0.78      0.80      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = lst_ensemble[1].drop(\"Exited\", axis=1)\n",
    "y = lst_ensemble[1][\"Exited\"]\n",
    "y_pred2 = ANN(X, X_test,y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 900us/step - loss: 0.6803 - accuracy: 0.5565\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 864us/step - loss: 0.6633 - accuracy: 0.6143\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.6544 - accuracy: 0.6474\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 876us/step - loss: 0.6477 - accuracy: 0.6560\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 801us/step - loss: 0.6410 - accuracy: 0.6548\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 839us/step - loss: 0.6348 - accuracy: 0.6671\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 828us/step - loss: 0.6294 - accuracy: 0.6732\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 765us/step - loss: 0.6247 - accuracy: 0.6708\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 864us/step - loss: 0.6208 - accuracy: 0.6708\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 799us/step - loss: 0.6163 - accuracy: 0.6757\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 848us/step - loss: 0.6136 - accuracy: 0.6708\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 846us/step - loss: 0.6107 - accuracy: 0.6769\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 783us/step - loss: 0.6079 - accuracy: 0.6781\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 881us/step - loss: 0.6068 - accuracy: 0.6769\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 754us/step - loss: 0.6034 - accuracy: 0.6830\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 778us/step - loss: 0.6009 - accuracy: 0.6794\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 797us/step - loss: 0.5995 - accuracy: 0.6806\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 807us/step - loss: 0.5973 - accuracy: 0.6818\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 794us/step - loss: 0.5954 - accuracy: 0.6867\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 750us/step - loss: 0.5941 - accuracy: 0.6880\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 760us/step - loss: 0.5907 - accuracy: 0.6880\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 813us/step - loss: 0.5890 - accuracy: 0.6867\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 911us/step - loss: 0.5868 - accuracy: 0.6880\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6941\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.6880\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 842us/step - loss: 0.5825 - accuracy: 0.6916\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 762us/step - loss: 0.5808 - accuracy: 0.6953\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 754us/step - loss: 0.5791 - accuracy: 0.6916\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 767us/step - loss: 0.5767 - accuracy: 0.6966\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 777us/step - loss: 0.5755 - accuracy: 0.6966\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 775us/step - loss: 0.5744 - accuracy: 0.7002\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 793us/step - loss: 0.5723 - accuracy: 0.6953\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 810us/step - loss: 0.5711 - accuracy: 0.6941\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 782us/step - loss: 0.5689 - accuracy: 0.7015\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 794us/step - loss: 0.5678 - accuracy: 0.7076\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 764us/step - loss: 0.5669 - accuracy: 0.6966\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 779us/step - loss: 0.5664 - accuracy: 0.7088\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 853us/step - loss: 0.5629 - accuracy: 0.7101\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 773us/step - loss: 0.5615 - accuracy: 0.7076\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 750us/step - loss: 0.5602 - accuracy: 0.7125\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 865us/step - loss: 0.5584 - accuracy: 0.7076\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 790us/step - loss: 0.5572 - accuracy: 0.7150\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.7150\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 761us/step - loss: 0.5556 - accuracy: 0.7076\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 757us/step - loss: 0.5526 - accuracy: 0.7101\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 781us/step - loss: 0.5518 - accuracy: 0.7162\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 767us/step - loss: 0.5498 - accuracy: 0.7138\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 747us/step - loss: 0.5491 - accuracy: 0.7113\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 777us/step - loss: 0.5492 - accuracy: 0.7125\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 755us/step - loss: 0.5465 - accuracy: 0.7162\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 742us/step - loss: 0.5464 - accuracy: 0.7211\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 846us/step - loss: 0.5441 - accuracy: 0.7125\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 757us/step - loss: 0.5435 - accuracy: 0.7187\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 766us/step - loss: 0.5440 - accuracy: 0.7187\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7187\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7199\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 804us/step - loss: 0.5400 - accuracy: 0.7174\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 789us/step - loss: 0.5389 - accuracy: 0.7199\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 800us/step - loss: 0.5377 - accuracy: 0.7187\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 756us/step - loss: 0.5370 - accuracy: 0.7297\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 817us/step - loss: 0.5373 - accuracy: 0.7211\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 750us/step - loss: 0.5345 - accuracy: 0.7211\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 835us/step - loss: 0.5342 - accuracy: 0.7260\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 799us/step - loss: 0.5330 - accuracy: 0.7248\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 757us/step - loss: 0.5313 - accuracy: 0.7224\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 830us/step - loss: 0.5305 - accuracy: 0.7297\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 757us/step - loss: 0.5299 - accuracy: 0.7248\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 800us/step - loss: 0.5289 - accuracy: 0.7334\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 812us/step - loss: 0.5280 - accuracy: 0.7359\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 766us/step - loss: 0.5282 - accuracy: 0.7346\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 775us/step - loss: 0.5262 - accuracy: 0.7297\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 834us/step - loss: 0.5258 - accuracy: 0.7420\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 719us/step - loss: 0.5253 - accuracy: 0.7322\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 753us/step - loss: 0.5261 - accuracy: 0.7236\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 757us/step - loss: 0.5252 - accuracy: 0.7273\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 825us/step - loss: 0.5223 - accuracy: 0.7346\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 783us/step - loss: 0.5227 - accuracy: 0.7408\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 823us/step - loss: 0.5214 - accuracy: 0.7322\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 726us/step - loss: 0.5205 - accuracy: 0.7346\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 766us/step - loss: 0.5209 - accuracy: 0.7322\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 793us/step - loss: 0.5187 - accuracy: 0.7346\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7383\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.7420\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 834us/step - loss: 0.5172 - accuracy: 0.7383\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 931us/step - loss: 0.5168 - accuracy: 0.7383\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 800us/step - loss: 0.5150 - accuracy: 0.7334\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 749us/step - loss: 0.5145 - accuracy: 0.7383\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 740us/step - loss: 0.5140 - accuracy: 0.7371\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 782us/step - loss: 0.5130 - accuracy: 0.7396\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 749us/step - loss: 0.5132 - accuracy: 0.7445\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 765us/step - loss: 0.5131 - accuracy: 0.7408\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 725us/step - loss: 0.5108 - accuracy: 0.7445\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 786us/step - loss: 0.5094 - accuracy: 0.7383\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 757us/step - loss: 0.5087 - accuracy: 0.7445\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 764us/step - loss: 0.5092 - accuracy: 0.7408\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 781us/step - loss: 0.5074 - accuracy: 0.7494\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 783us/step - loss: 0.5078 - accuracy: 0.7506\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 811us/step - loss: 0.5067 - accuracy: 0.7445\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 770us/step - loss: 0.5060 - accuracy: 0.7469\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 746us/step - loss: 0.5044 - accuracy: 0.7482\n",
      "250/250 [==============================] - 0s 507us/step - loss: 0.5709 - accuracy: 0.7176\n",
      "250/250 [==============================] - 0s 487us/step\n",
      "[[4589 1781]\n",
      " [ 478 1152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80      6370\n",
      "           1       0.39      0.71      0.50      1630\n",
      "\n",
      "    accuracy                           0.72      8000\n",
      "   macro avg       0.65      0.71      0.65      8000\n",
      "weighted avg       0.80      0.72      0.74      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = lst_ensemble[2].drop(\"Exited\", axis=1)\n",
    "y = lst_ensemble[2][\"Exited\"]\n",
    "y_pred3 = ANN(X, X_test,y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_pred1.copy()\n",
    "for i in range(len(y_pred_final)):\n",
    "    num = y_pred1[i] + y_pred2[i] + y_pred3[i]\n",
    "    if num >= 1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.65      0.76      6370\n",
      "           1       0.37      0.80      0.50      1630\n",
      "\n",
      "    accuracy                           0.68      8000\n",
      "   macro avg       0.65      0.73      0.63      8000\n",
      "weighted avg       0.81      0.68      0.71      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff7d574ff54b0f83d103cd6ae016c78af2d72d27cb5ffce6ccc74920cc77be9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
