{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use digits mnist dataset and fashion mnist dataset to build an Artificial Neural Network (ANN) and Conventional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 16:25:02.519671: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = digits.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdbb59ef8b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 16:25:09.001969: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.Dense(20, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                15700     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,910\n",
      "Trainable params: 15,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",           \n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 662us/step - loss: 0.4019 - accuracy: 0.8862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbb63f6250>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 528us/step - loss: 0.2410 - accuracy: 0.9308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2409939020872116, 0.9308000206947327]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 457us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 954,    0,    0,    1,    1,    9,   10,    3,    2,    0],\n",
       "       [   0, 1118,    2,    2,    0,    1,    3,    1,    7,    1],\n",
       "       [   6,    6,  953,    8,   12,    5,    8,    8,   24,    2],\n",
       "       [   4,    2,   19,  903,    3,   35,    1,   11,   22,   10],\n",
       "       [   1,    2,    3,    0,  939,    0,    9,    2,    6,   20],\n",
       "       [   5,    4,    0,   16,    8,  816,    8,    7,   21,    7],\n",
       "       [   7,    3,    4,    0,   10,   24,  904,    1,    5,    0],\n",
       "       [   2,    9,   26,    3,    7,    1,    0,  944,    2,   34],\n",
       "       [   3,    9,    9,   16,   15,   28,    6,   13,  863,   12],\n",
       "       [  10,    9,    1,    7,   44,    7,    1,   13,    3,  914]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [np.argmax(i) for i in y_pred]\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 459us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       980\n",
      "           1       0.96      0.99      0.97      1135\n",
      "           2       0.94      0.92      0.93      1032\n",
      "           3       0.94      0.89      0.92      1010\n",
      "           4       0.90      0.96      0.93       982\n",
      "           5       0.88      0.91      0.90       892\n",
      "           6       0.95      0.94      0.95       958\n",
      "           7       0.94      0.92      0.93      1028\n",
      "           8       0.90      0.89      0.89       974\n",
      "           9       0.91      0.91      0.91      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [np.argmax(i) for i in y_pred]\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 450us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conventional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(30, (3, 3), activation = 'relu', input_shape=(28,28,1)),\n",
    "    keras.layers.MaxPool2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(20, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",           \n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2120 - accuracy: 0.9371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdba353cca0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.96      0.97      1032\n",
      "           3       0.99      0.97      0.98      1010\n",
      "           4       0.99      0.97      0.98       982\n",
      "           5       0.98      0.97      0.98       892\n",
      "           6       0.98      0.97      0.98       958\n",
      "           7       0.96      0.97      0.97      1028\n",
      "           8       0.93      0.98      0.95       974\n",
      "           9       0.97      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [np.argmax(i) for i in y_pred]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use fashion mnist dataset and fashion mnist dataset to build an Artificial Neural Network (ANN) and Conventional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdbb65567f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[train_labels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4742 - accuracy: 0.8303\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3581 - accuracy: 0.8698\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3237 - accuracy: 0.8804\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2987 - accuracy: 0.8884\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2789 - accuracy: 0.8956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdb90b0e940>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[np.argmax(model.predict(test_images)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[test_labels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(30, (3, 3), activation = 'relu', input_shape=(28,28,1)),\n",
    "    keras.layers.MaxPool2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.3808 - accuracy: 0.8636\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 23s 13ms/step - loss: 0.2516 - accuracy: 0.9086\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2035 - accuracy: 0.9254\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1655 - accuracy: 0.9385\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.1327 - accuracy: 0.9511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdba3665be0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[np.argmax(model.predict(test_images)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[test_labels[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take this dataset for bank customer churn prediction : https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
    "\n",
    "i. Build a deep learning model to predict churn rate at bank. <br>\n",
    "ii. Once model is built, print classification report and analyze precision, recall and f1-score <br>\n",
    "iii. Improve f1 score in minority class using various techniques such as undersampling, oversampling, ensemble etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>682</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>178373.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>667</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88890.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>558</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>111363.10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197264.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>469</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>186490.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>712</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>100606.02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165693.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "7583          682    France   Male   26       8       0.00              2   \n",
       "3539          667    France   Male   42       6       0.00              1   \n",
       "3298          558   Germany   Male   25      10  111363.10              2   \n",
       "8712          469     Spain   Male   35       5       0.00              2   \n",
       "4440          712    France   Male   32       9  100606.02              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "7583          1               0        178373.43       0  \n",
       "3539          1               0         88890.05       0  \n",
       "3298          1               0        197264.35       0  \n",
       "8712          1               0        186490.37       0  \n",
       "4440          1               0        165693.06       0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped = df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1)\n",
    "df_dropped.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1                  0   \n",
       "1                  1        112542.58       0                  0   \n",
       "2                  0        113931.57       1                  0   \n",
       "3                  0         93826.63       0                  0   \n",
       "4                  1         79084.10       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0                  0   \n",
       "9996               1        101699.77       0                  0   \n",
       "9997               1         42085.58       1                  0   \n",
       "9998               0         92888.52       1                  1   \n",
       "9999               0         38190.78       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_dummies = pd.get_dummies(data=df_dropped, drop_first=True)\n",
    "df_with_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore            int64\n",
       "Age                    int64\n",
       "Tenure                 int64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Exited                 int64\n",
       "Geography_Germany      uint8\n",
       "Geography_Spain        uint8\n",
       "Gender_Male            uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_dummies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0           0.538  0.324324     0.2  0.000000       0.000000          1   \n",
       "1           0.516  0.310811     0.1  0.334031       0.000000          0   \n",
       "2           0.304  0.324324     0.8  0.636357       0.666667          1   \n",
       "3           0.698  0.283784     0.1  0.000000       0.333333          0   \n",
       "4           1.000  0.337838     0.2  0.500246       0.000000          1   \n",
       "...           ...       ...     ...       ...            ...        ...   \n",
       "9995        0.842  0.283784     0.5  0.000000       0.333333          1   \n",
       "9996        0.332  0.229730     1.0  0.228657       0.000000          1   \n",
       "9997        0.718  0.243243     0.7  0.000000       0.000000          0   \n",
       "9998        0.844  0.324324     0.3  0.299226       0.333333          1   \n",
       "9999        0.884  0.135135     0.4  0.518708       0.000000          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1         0.506735       1                  0   \n",
       "1                  1         0.562709       0                  0   \n",
       "2                  0         0.569654       1                  0   \n",
       "3                  0         0.469120       0                  0   \n",
       "4                  1         0.395400       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         0.481341       0                  0   \n",
       "9996               1         0.508490       0                  0   \n",
       "9997               1         0.210390       1                  0   \n",
       "9998               0         0.464429       1                  1   \n",
       "9999               0         0.190914       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "columns_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = MinMaxScaler()\n",
    "df_with_dummies[columns_to_scale] = scaler.fit_transform(df_with_dummies[columns_to_scale])\n",
    "df_with_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_with_dummies.drop(\"Exited\", axis=1)\n",
    "y = df_with_dummies[\"Exited\"]\n",
    "X_test, X_train, y_test, y_train= train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, X_test, y_train, y_test):\n",
    "    model= keras.Sequential([\n",
    "        keras.layers.Dense(11, activation='relu', input_dim=11),\n",
    "        keras.layers.Dense(5, activation='relu'),\n",
    "        keras.layers.Dense(1, activation= 'sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100)\n",
    "    model.evaluate(X_test, y_test)\n",
    "    y_pred= np.round(model.predict(X_test))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return y_pred\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 784us/step - loss: 0.5655 - accuracy: 0.7965\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 718us/step - loss: 0.5071 - accuracy: 0.7965\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 725us/step - loss: 0.4912 - accuracy: 0.7965\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 738us/step - loss: 0.4795 - accuracy: 0.7975\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 716us/step - loss: 0.4709 - accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 880us/step - loss: 0.4653 - accuracy: 0.8020\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.8045\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.4575 - accuracy: 0.8065\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 685us/step - loss: 0.4544 - accuracy: 0.8080\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 709us/step - loss: 0.4528 - accuracy: 0.8085\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 678us/step - loss: 0.4495 - accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 661us/step - loss: 0.4476 - accuracy: 0.8110\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 651us/step - loss: 0.4459 - accuracy: 0.8110\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 671us/step - loss: 0.4433 - accuracy: 0.8115\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 660us/step - loss: 0.4415 - accuracy: 0.8120\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 700us/step - loss: 0.4405 - accuracy: 0.8170\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 668us/step - loss: 0.4380 - accuracy: 0.8180\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 667us/step - loss: 0.4366 - accuracy: 0.8175\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 675us/step - loss: 0.4350 - accuracy: 0.8160\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 931us/step - loss: 0.4335 - accuracy: 0.8180\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.4316 - accuracy: 0.8165\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 677us/step - loss: 0.4318 - accuracy: 0.8150\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 657us/step - loss: 0.4294 - accuracy: 0.8180\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8185\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 772us/step - loss: 0.4285 - accuracy: 0.8155\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 657us/step - loss: 0.4250 - accuracy: 0.8195\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 654us/step - loss: 0.4244 - accuracy: 0.8190\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 658us/step - loss: 0.4240 - accuracy: 0.8205\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 659us/step - loss: 0.4214 - accuracy: 0.8220\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 676us/step - loss: 0.4207 - accuracy: 0.8210\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 737us/step - loss: 0.4191 - accuracy: 0.8175\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 668us/step - loss: 0.4184 - accuracy: 0.8195\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 660us/step - loss: 0.4176 - accuracy: 0.8215\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 664us/step - loss: 0.4152 - accuracy: 0.8180\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.4130 - accuracy: 0.8180\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 671us/step - loss: 0.4127 - accuracy: 0.8205\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 659us/step - loss: 0.4110 - accuracy: 0.8215\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 660us/step - loss: 0.4099 - accuracy: 0.8220\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 693us/step - loss: 0.4093 - accuracy: 0.8185\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 851us/step - loss: 0.4072 - accuracy: 0.8235\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 682us/step - loss: 0.4075 - accuracy: 0.8230\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 662us/step - loss: 0.4051 - accuracy: 0.8245\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 658us/step - loss: 0.4036 - accuracy: 0.8275\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 680us/step - loss: 0.4018 - accuracy: 0.8215\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 659us/step - loss: 0.4021 - accuracy: 0.8235\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 660us/step - loss: 0.3992 - accuracy: 0.8260\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.3991 - accuracy: 0.8270\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 651us/step - loss: 0.3978 - accuracy: 0.8275\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 693us/step - loss: 0.3969 - accuracy: 0.8215\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 663us/step - loss: 0.3947 - accuracy: 0.8275\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 675us/step - loss: 0.3951 - accuracy: 0.8250\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 662us/step - loss: 0.3916 - accuracy: 0.8255\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 669us/step - loss: 0.3937 - accuracy: 0.8285\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 662us/step - loss: 0.3890 - accuracy: 0.8310\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 666us/step - loss: 0.3890 - accuracy: 0.8255\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 669us/step - loss: 0.3869 - accuracy: 0.8310\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3838 - accuracy: 0.8350\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 868us/step - loss: 0.3828 - accuracy: 0.8355\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 679us/step - loss: 0.3818 - accuracy: 0.8310\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 666us/step - loss: 0.3817 - accuracy: 0.8340\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 660us/step - loss: 0.3784 - accuracy: 0.8390\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 674us/step - loss: 0.3770 - accuracy: 0.8370\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 673us/step - loss: 0.3755 - accuracy: 0.8340\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 694us/step - loss: 0.3741 - accuracy: 0.8410\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 664us/step - loss: 0.3726 - accuracy: 0.8415\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 666us/step - loss: 0.3714 - accuracy: 0.8405\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 682us/step - loss: 0.3698 - accuracy: 0.8450\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 654us/step - loss: 0.3682 - accuracy: 0.8410\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 721us/step - loss: 0.3689 - accuracy: 0.8445\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 670us/step - loss: 0.3662 - accuracy: 0.8450\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 669us/step - loss: 0.3662 - accuracy: 0.8440\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 664us/step - loss: 0.3638 - accuracy: 0.8445\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 668us/step - loss: 0.3634 - accuracy: 0.8445\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 656us/step - loss: 0.3625 - accuracy: 0.8410\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 658us/step - loss: 0.3606 - accuracy: 0.8440\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 667us/step - loss: 0.3615 - accuracy: 0.8440\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 652us/step - loss: 0.3591 - accuracy: 0.8470\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 651us/step - loss: 0.3567 - accuracy: 0.8440\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 662us/step - loss: 0.3579 - accuracy: 0.8440\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 664us/step - loss: 0.3566 - accuracy: 0.8465\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8450\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 800us/step - loss: 0.3537 - accuracy: 0.8500\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 667us/step - loss: 0.3530 - accuracy: 0.8520\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 660us/step - loss: 0.3529 - accuracy: 0.8520\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 668us/step - loss: 0.3519 - accuracy: 0.8490\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 658us/step - loss: 0.3505 - accuracy: 0.8490\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 661us/step - loss: 0.3504 - accuracy: 0.8500\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 653us/step - loss: 0.3497 - accuracy: 0.8515\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 653us/step - loss: 0.3488 - accuracy: 0.8500\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 655us/step - loss: 0.3487 - accuracy: 0.8510\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 641us/step - loss: 0.3472 - accuracy: 0.8520\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 668us/step - loss: 0.3484 - accuracy: 0.8520\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 658us/step - loss: 0.3469 - accuracy: 0.8555\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 650us/step - loss: 0.3458 - accuracy: 0.8545\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 650us/step - loss: 0.3462 - accuracy: 0.8535\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 656us/step - loss: 0.3448 - accuracy: 0.8580\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 671us/step - loss: 0.3452 - accuracy: 0.8550\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 709us/step - loss: 0.3448 - accuracy: 0.8555\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 673us/step - loss: 0.3439 - accuracy: 0.8550\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 674us/step - loss: 0.3450 - accuracy: 0.8580\n",
      "250/250 [==============================] - 0s 493us/step - loss: 0.3642 - accuracy: 0.8519\n",
      "250/250 [==============================] - 0s 537us/step\n",
      "[[6139  231]\n",
      " [ 954  676]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      6370\n",
      "           1       0.75      0.41      0.53      1630\n",
      "\n",
      "    accuracy                           0.85      8000\n",
      "   macro avg       0.81      0.69      0.72      8000\n",
      "weighted avg       0.84      0.85      0.83      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(X_train, X_test, y_train, y_test) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>0.220</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.476319</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457789</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8167</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.588634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607963</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>0.626</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.404408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217804</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.711785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9107</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8249</th>\n",
       "      <td>0.472</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8337</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.467497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470924</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.495535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "1344        0.220  0.297297     0.6  0.476319       0.333333          1   \n",
       "8167        0.726  0.081081     0.7  0.588634       0.000000          1   \n",
       "4747        0.626  0.621622     0.6  0.000000       0.333333          0   \n",
       "5004        0.304  0.527027     0.3  0.404408       0.000000          1   \n",
       "3124        0.820  0.283784     0.6  0.711785       0.000000          1   \n",
       "...           ...       ...     ...       ...            ...        ...   \n",
       "9107        0.610  0.270270     0.9  0.000000       0.000000          0   \n",
       "8249        0.472  0.270270     0.6  0.000000       0.333333          1   \n",
       "8337        0.368  0.310811     0.9  0.000000       0.333333          1   \n",
       "6279        0.814  0.500000     0.9  0.467497       1.000000          1   \n",
       "412         0.790  0.175676     0.3  0.495535       0.000000          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "1344               0         0.457789                  1                0   \n",
       "8167               1         0.607963                  1                0   \n",
       "4747               1         0.079332                  0                1   \n",
       "5004               0         0.217804                  1                0   \n",
       "3124               0         0.335631                  0                0   \n",
       "...              ...              ...                ...              ...   \n",
       "9107               1         0.452437                  0                1   \n",
       "8249               1         0.189639                  0                0   \n",
       "8337               0         0.069305                  0                0   \n",
       "6279               0         0.470924                  0                1   \n",
       "412                1         0.702267                  0                1   \n",
       "\n",
       "      Gender_Male  Exited  \n",
       "1344            0       1  \n",
       "8167            0       0  \n",
       "4747            1       0  \n",
       "5004            0       1  \n",
       "3124            1       1  \n",
       "...           ...     ...  \n",
       "9107            1       0  \n",
       "8249            0       0  \n",
       "8337            1       0  \n",
       "6279            0       1  \n",
       "412             0       0  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.concat([X_train, y_train], axis=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = new_df[new_df.Exited==0]\n",
    "df_1 = new_df[new_df.Exited==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, 407)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_0), len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948451</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.738862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323368</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>0.462</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.415976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.149645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>0.388</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>0.168</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367787</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7223</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.616134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>0.720</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.373287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.467497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470924</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "3526        0.898  0.162162     0.9  0.000000       0.333333          1   \n",
       "8575        0.470  0.364865     0.0  0.000000       0.333333          0   \n",
       "8053        0.672  0.148649     0.3  0.738862       0.000000          1   \n",
       "6623        0.462  0.135135     0.3  0.415976       0.000000          1   \n",
       "4456        0.388  0.297297     0.8  0.000000       0.333333          1   \n",
       "...           ...       ...     ...       ...            ...        ...   \n",
       "8379        0.168  0.500000     0.6  0.000000       0.000000          0   \n",
       "7223        0.898  0.175676     0.9  0.616134       0.000000          0   \n",
       "1046        0.914  0.324324     0.1  0.000000       0.000000          1   \n",
       "1487        0.720  0.445946     0.4  0.373287       0.000000          0   \n",
       "6279        0.814  0.500000     0.9  0.467497       1.000000          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "3526               0         0.684147                  0                0   \n",
       "8575               0         0.948451                  0                1   \n",
       "8053               0         0.323368                  1                0   \n",
       "6623               1         0.149645                  0                0   \n",
       "4456               0         0.307878                  0                0   \n",
       "...              ...              ...                ...              ...   \n",
       "8379               1         0.367787                  0                1   \n",
       "7223               1         0.443009                  1                0   \n",
       "1046               0         0.082453                  0                1   \n",
       "1487               1         0.707012                  0                1   \n",
       "6279               0         0.470924                  0                1   \n",
       "\n",
       "      Gender_Male  Exited  \n",
       "3526            0       0  \n",
       "8575            1       0  \n",
       "8053            1       0  \n",
       "6623            1       0  \n",
       "4456            1       0  \n",
       "...           ...     ...  \n",
       "8379            1       1  \n",
       "7223            1       1  \n",
       "1046            0       1  \n",
       "1487            0       1  \n",
       "6279            0       1  \n",
       "\n",
       "[814 rows x 12 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df_0.sample(407)\n",
    "df_undersampled = pd.concat([df_0, df_1], axis=0)\n",
    "df_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 895us/step - loss: 0.6929 - accuracy: 0.4902\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 767us/step - loss: 0.6925 - accuracy: 0.4939\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 760us/step - loss: 0.6924 - accuracy: 0.5025\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 753us/step - loss: 0.6923 - accuracy: 0.5012\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5074\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 762us/step - loss: 0.6920 - accuracy: 0.5098\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.6918 - accuracy: 0.5111\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 723us/step - loss: 0.6915 - accuracy: 0.5098\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 714us/step - loss: 0.6911 - accuracy: 0.5184\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 732us/step - loss: 0.6907 - accuracy: 0.5135\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.6902 - accuracy: 0.5258\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 696us/step - loss: 0.6884 - accuracy: 0.5405\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 702us/step - loss: 0.6821 - accuracy: 0.5676\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 712us/step - loss: 0.6748 - accuracy: 0.5971\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 726us/step - loss: 0.6707 - accuracy: 0.6069\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.6655 - accuracy: 0.6314\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 713us/step - loss: 0.6635 - accuracy: 0.6474\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.6589 - accuracy: 0.6634\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 928us/step - loss: 0.6557 - accuracy: 0.6425\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6572\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 741us/step - loss: 0.6512 - accuracy: 0.6720\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.6472 - accuracy: 0.6658\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.6449 - accuracy: 0.6646\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 722us/step - loss: 0.6426 - accuracy: 0.6683\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 722us/step - loss: 0.6398 - accuracy: 0.6732\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 734us/step - loss: 0.6374 - accuracy: 0.6720\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 713us/step - loss: 0.6360 - accuracy: 0.6732\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6744\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 730us/step - loss: 0.6301 - accuracy: 0.6806\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.6279 - accuracy: 0.6818\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 700us/step - loss: 0.6274 - accuracy: 0.6843\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.6243 - accuracy: 0.6867\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 705us/step - loss: 0.6212 - accuracy: 0.6867\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 701us/step - loss: 0.6186 - accuracy: 0.6855\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.6172 - accuracy: 0.6941\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 690us/step - loss: 0.6145 - accuracy: 0.6978\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 691us/step - loss: 0.6134 - accuracy: 0.6941\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 668us/step - loss: 0.6110 - accuracy: 0.6990\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 669us/step - loss: 0.6083 - accuracy: 0.6978\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 704us/step - loss: 0.6064 - accuracy: 0.7015\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 687us/step - loss: 0.6045 - accuracy: 0.7027\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 698us/step - loss: 0.6028 - accuracy: 0.6978\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 737us/step - loss: 0.5998 - accuracy: 0.6966\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.5987 - accuracy: 0.7027\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 688us/step - loss: 0.5972 - accuracy: 0.6978\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 693us/step - loss: 0.5949 - accuracy: 0.7064\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 727us/step - loss: 0.5930 - accuracy: 0.7138\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 677us/step - loss: 0.5908 - accuracy: 0.7039\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5901 - accuracy: 0.7039\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 677us/step - loss: 0.5878 - accuracy: 0.7027\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5857 - accuracy: 0.7039\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 679us/step - loss: 0.5852 - accuracy: 0.7064\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 720us/step - loss: 0.5824 - accuracy: 0.7150\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.7125\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.7052\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 709us/step - loss: 0.5780 - accuracy: 0.7199\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.5759 - accuracy: 0.7187\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.5756 - accuracy: 0.7211\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 891us/step - loss: 0.5720 - accuracy: 0.7248\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.5707 - accuracy: 0.7297\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 701us/step - loss: 0.5701 - accuracy: 0.7174\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 696us/step - loss: 0.5692 - accuracy: 0.7174\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 702us/step - loss: 0.5670 - accuracy: 0.7236\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 676us/step - loss: 0.5653 - accuracy: 0.7310\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5640 - accuracy: 0.7199\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 681us/step - loss: 0.5626 - accuracy: 0.7260\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.5613 - accuracy: 0.7248\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 751us/step - loss: 0.5609 - accuracy: 0.7285\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 705us/step - loss: 0.5583 - accuracy: 0.7260\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5575 - accuracy: 0.7199\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 682us/step - loss: 0.5562 - accuracy: 0.7285\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 685us/step - loss: 0.5559 - accuracy: 0.7224\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7285\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 828us/step - loss: 0.5528 - accuracy: 0.7310\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 704us/step - loss: 0.5513 - accuracy: 0.7236\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5516 - accuracy: 0.7236\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 684us/step - loss: 0.5494 - accuracy: 0.7371\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5471 - accuracy: 0.7322\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 701us/step - loss: 0.5483 - accuracy: 0.7371\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 702us/step - loss: 0.5473 - accuracy: 0.7297\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 683us/step - loss: 0.5449 - accuracy: 0.7396\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 714us/step - loss: 0.5433 - accuracy: 0.7359\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 726us/step - loss: 0.5415 - accuracy: 0.7322\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 712us/step - loss: 0.5405 - accuracy: 0.7383\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 701us/step - loss: 0.5394 - accuracy: 0.7371\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 736us/step - loss: 0.5390 - accuracy: 0.7334\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 714us/step - loss: 0.5378 - accuracy: 0.7359\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.5369 - accuracy: 0.7346\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 723us/step - loss: 0.5368 - accuracy: 0.7359\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 721us/step - loss: 0.5359 - accuracy: 0.7383\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5352 - accuracy: 0.7383\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 723us/step - loss: 0.5345 - accuracy: 0.7420\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 709us/step - loss: 0.5320 - accuracy: 0.7396\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 706us/step - loss: 0.5328 - accuracy: 0.7383\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 857us/step - loss: 0.5315 - accuracy: 0.7371\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7420\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.7396\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 740us/step - loss: 0.5285 - accuracy: 0.7383\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 704us/step - loss: 0.5264 - accuracy: 0.7432\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5252 - accuracy: 0.7408\n",
      "250/250 [==============================] - 0s 494us/step - loss: 0.5664 - accuracy: 0.7368\n",
      "250/250 [==============================] - 0s 412us/step\n",
      "[[4783 1587]\n",
      " [ 519 1111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82      6370\n",
      "           1       0.41      0.68      0.51      1630\n",
      "\n",
      "    accuracy                           0.74      8000\n",
      "   macro avg       0.66      0.72      0.67      8000\n",
      "weighted avg       0.80      0.74      0.76      8000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_undersampled.drop(\"Exited\", axis=1)\n",
    "y = df_undersampled[\"Exited\"]\n",
    "ANN(X, X_test,y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = new_df[new_df.Exited==0]\n",
    "df_1 = new_df[new_df.Exited==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, 407)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_0), len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.sample(1593, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, 1593)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_0), len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8167</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.588634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607963</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>0.626</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>0.634</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.344344</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>0.416</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443858</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986358</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.351302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548290</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>0.716</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504544</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.663656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7337</th>\n",
       "      <td>0.652</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.330449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.348</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.429731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998664</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.441622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.175453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3186 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "8167        0.726  0.081081     0.7  0.588634       0.000000          1   \n",
       "4747        0.626  0.621622     0.6  0.000000       0.333333          0   \n",
       "2090        0.634  0.283784     0.9  0.000000       0.333333          1   \n",
       "3298        0.416  0.094595     1.0  0.443858       0.333333          1   \n",
       "9485        1.000  0.256757     0.4  0.351302       0.000000          1   \n",
       "...           ...       ...     ...       ...            ...        ...   \n",
       "4619        0.716  0.391892     0.0  0.504544       0.333333          0   \n",
       "7337        0.652  0.216216     0.8  0.330449       0.000000          1   \n",
       "118         0.348  0.175676     0.8  0.429731       0.000000          1   \n",
       "1447        0.694  0.513514     0.5  0.441622       0.000000          1   \n",
       "2080        0.742  0.500000     0.3  0.175453       0.000000          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "8167               1         0.607963                  1                0   \n",
       "4747               1         0.079332                  0                1   \n",
       "2090               0         0.344344                  0                1   \n",
       "3298               0         0.986358                  1                0   \n",
       "9485               0         0.548290                  0                1   \n",
       "...              ...              ...                ...              ...   \n",
       "4619               1         0.663656                  0                0   \n",
       "7337               0         0.459073                  0                0   \n",
       "118                0         0.998664                  1                0   \n",
       "1447               1         0.251118                  0                1   \n",
       "2080               0         0.329296                  0                0   \n",
       "\n",
       "      Gender_Male  Exited  \n",
       "8167            0       0  \n",
       "4747            1       0  \n",
       "2090            1       0  \n",
       "3298            1       0  \n",
       "9485            1       0  \n",
       "...           ...     ...  \n",
       "4619            0       1  \n",
       "7337            0       1  \n",
       "118             0       1  \n",
       "1447            1       1  \n",
       "2080            0       1  \n",
       "\n",
       "[3186 rows x 12 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oversampled = pd.concat([df_0, df_1])\n",
    "df_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 741us/step - loss: 0.7039 - accuracy: 0.5050\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 676us/step - loss: 0.6758 - accuracy: 0.5860\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 659us/step - loss: 0.6548 - accuracy: 0.6312\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 663us/step - loss: 0.6285 - accuracy: 0.6591\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 649us/step - loss: 0.6118 - accuracy: 0.6695\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.6008 - accuracy: 0.6745\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 652us/step - loss: 0.5912 - accuracy: 0.6811\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 643us/step - loss: 0.5830 - accuracy: 0.6830\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 649us/step - loss: 0.5764 - accuracy: 0.6830\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 642us/step - loss: 0.5700 - accuracy: 0.6864\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 640us/step - loss: 0.5655 - accuracy: 0.6943\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 638us/step - loss: 0.5605 - accuracy: 0.7009\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 786us/step - loss: 0.5578 - accuracy: 0.7094\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 658us/step - loss: 0.5535 - accuracy: 0.7103\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 648us/step - loss: 0.5512 - accuracy: 0.7166\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 942us/step - loss: 0.5481 - accuracy: 0.7169\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 640us/step - loss: 0.5456 - accuracy: 0.7194\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 643us/step - loss: 0.5430 - accuracy: 0.7241\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 640us/step - loss: 0.5410 - accuracy: 0.7250\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 653us/step - loss: 0.5393 - accuracy: 0.7294\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 659us/step - loss: 0.5381 - accuracy: 0.7298\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.5354 - accuracy: 0.7301\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 659us/step - loss: 0.5338 - accuracy: 0.7341\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 662us/step - loss: 0.5310 - accuracy: 0.7332\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 654us/step - loss: 0.5289 - accuracy: 0.7348\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.5258 - accuracy: 0.7385\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 658us/step - loss: 0.5225 - accuracy: 0.7426\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 658us/step - loss: 0.5197 - accuracy: 0.7404\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 662us/step - loss: 0.5180 - accuracy: 0.7442\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 661us/step - loss: 0.5157 - accuracy: 0.7448\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 663us/step - loss: 0.5117 - accuracy: 0.7414\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 661us/step - loss: 0.5094 - accuracy: 0.7467\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 838us/step - loss: 0.5069 - accuracy: 0.7502\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 724us/step - loss: 0.5031 - accuracy: 0.7508\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 647us/step - loss: 0.5009 - accuracy: 0.7489\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 641us/step - loss: 0.4972 - accuracy: 0.7505\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 625us/step - loss: 0.4944 - accuracy: 0.7536\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 645us/step - loss: 0.4925 - accuracy: 0.7530\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 641us/step - loss: 0.4888 - accuracy: 0.7599\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 638us/step - loss: 0.4861 - accuracy: 0.7564\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 646us/step - loss: 0.4825 - accuracy: 0.7602\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 642us/step - loss: 0.4799 - accuracy: 0.7627\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 651us/step - loss: 0.4778 - accuracy: 0.7646\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 637us/step - loss: 0.4750 - accuracy: 0.7693\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 636us/step - loss: 0.4725 - accuracy: 0.7662\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.4711 - accuracy: 0.7671\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 639us/step - loss: 0.4700 - accuracy: 0.7684\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 637us/step - loss: 0.4666 - accuracy: 0.7699\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 643us/step - loss: 0.4654 - accuracy: 0.7702\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 636us/step - loss: 0.4624 - accuracy: 0.7746\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.4605 - accuracy: 0.7790\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 642us/step - loss: 0.4591 - accuracy: 0.7797\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 637us/step - loss: 0.4565 - accuracy: 0.7743\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 647us/step - loss: 0.4553 - accuracy: 0.7750\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 641us/step - loss: 0.4543 - accuracy: 0.7775\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 634us/step - loss: 0.4533 - accuracy: 0.7781\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 642us/step - loss: 0.4513 - accuracy: 0.7759\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.4483 - accuracy: 0.7790\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 644us/step - loss: 0.4495 - accuracy: 0.7822\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 645us/step - loss: 0.4467 - accuracy: 0.7831\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 648us/step - loss: 0.4441 - accuracy: 0.7806\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 636us/step - loss: 0.4452 - accuracy: 0.7850\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 638us/step - loss: 0.4422 - accuracy: 0.7834\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 638us/step - loss: 0.4407 - accuracy: 0.7850\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.4398 - accuracy: 0.7828\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 670us/step - loss: 0.4394 - accuracy: 0.7803\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 664us/step - loss: 0.4392 - accuracy: 0.7878\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 663us/step - loss: 0.4369 - accuracy: 0.7859\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 659us/step - loss: 0.4357 - accuracy: 0.7834\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.4361 - accuracy: 0.7881\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 661us/step - loss: 0.4351 - accuracy: 0.7847\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 658us/step - loss: 0.4333 - accuracy: 0.7859\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.4323 - accuracy: 0.7834\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 664us/step - loss: 0.4310 - accuracy: 0.7866\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 651us/step - loss: 0.4313 - accuracy: 0.7916\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 646us/step - loss: 0.4304 - accuracy: 0.7869\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 651us/step - loss: 0.4314 - accuracy: 0.7888\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 645us/step - loss: 0.4286 - accuracy: 0.7900\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 640us/step - loss: 0.4275 - accuracy: 0.7903\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 862us/step - loss: 0.4259 - accuracy: 0.7950\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 829us/step - loss: 0.4249 - accuracy: 0.7910\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 645us/step - loss: 0.4248 - accuracy: 0.7919\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 662us/step - loss: 0.4242 - accuracy: 0.7928\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 649us/step - loss: 0.4223 - accuracy: 0.7916\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 641us/step - loss: 0.4239 - accuracy: 0.7950\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 639us/step - loss: 0.4226 - accuracy: 0.7935\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 641us/step - loss: 0.4222 - accuracy: 0.7976\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 638us/step - loss: 0.4211 - accuracy: 0.7950\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 633us/step - loss: 0.4206 - accuracy: 0.7906\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 645us/step - loss: 0.4197 - accuracy: 0.7963\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 635us/step - loss: 0.4210 - accuracy: 0.7938\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 647us/step - loss: 0.4196 - accuracy: 0.7935\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 638us/step - loss: 0.4187 - accuracy: 0.7950\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 644us/step - loss: 0.4183 - accuracy: 0.7950\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 640us/step - loss: 0.4201 - accuracy: 0.7944\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 651us/step - loss: 0.4181 - accuracy: 0.7925\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.4168 - accuracy: 0.7972\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 907us/step - loss: 0.4170 - accuracy: 0.7947\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 635us/step - loss: 0.4159 - accuracy: 0.7991\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 651us/step - loss: 0.4161 - accuracy: 0.7910\n",
      "250/250 [==============================] - 0s 495us/step - loss: 0.4612 - accuracy: 0.7883\n",
      "250/250 [==============================] - 0s 422us/step\n",
      "[[5188 1182]\n",
      " [ 512 1118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86      6370\n",
      "           1       0.49      0.69      0.57      1630\n",
      "\n",
      "    accuracy                           0.79      8000\n",
      "   macro avg       0.70      0.75      0.71      8000\n",
      "weighted avg       0.82      0.79      0.80      8000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_oversampled.drop(\"Exited\", axis=1)\n",
    "y = df_oversampled[\"Exited\"]\n",
    "ANN(X, X_test,y, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 887us/step - loss: 0.6679 - accuracy: 0.6055\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 922us/step - loss: 0.6474 - accuracy: 0.6315\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 785us/step - loss: 0.6333 - accuracy: 0.6453\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 772us/step - loss: 0.6239 - accuracy: 0.6516\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 704us/step - loss: 0.6171 - accuracy: 0.6563\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 689us/step - loss: 0.6108 - accuracy: 0.6635\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 755us/step - loss: 0.6049 - accuracy: 0.6685\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 901us/step - loss: 0.6002 - accuracy: 0.6723\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 691us/step - loss: 0.5940 - accuracy: 0.6820\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.5869 - accuracy: 0.6877\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 723us/step - loss: 0.5818 - accuracy: 0.6937\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 734us/step - loss: 0.5748 - accuracy: 0.6971\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 809us/step - loss: 0.5695 - accuracy: 0.7081\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 701us/step - loss: 0.5646 - accuracy: 0.7122\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 730us/step - loss: 0.5588 - accuracy: 0.7144\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 706us/step - loss: 0.5558 - accuracy: 0.7166\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 713us/step - loss: 0.5486 - accuracy: 0.7207\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 678us/step - loss: 0.5428 - accuracy: 0.7219\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 681us/step - loss: 0.5389 - accuracy: 0.7247\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 745us/step - loss: 0.5328 - accuracy: 0.7279\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 748us/step - loss: 0.5284 - accuracy: 0.7379\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 762us/step - loss: 0.5230 - accuracy: 0.7423\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 696us/step - loss: 0.5169 - accuracy: 0.7476\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 706us/step - loss: 0.5115 - accuracy: 0.7464\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 987us/step - loss: 0.5063 - accuracy: 0.7498\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 702us/step - loss: 0.5004 - accuracy: 0.7520\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 751us/step - loss: 0.4954 - accuracy: 0.7524\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.4910 - accuracy: 0.7586\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 856us/step - loss: 0.4864 - accuracy: 0.7605\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.4827 - accuracy: 0.7602\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 769us/step - loss: 0.4794 - accuracy: 0.7643\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 739us/step - loss: 0.4757 - accuracy: 0.7677\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 796us/step - loss: 0.4737 - accuracy: 0.7630\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 711us/step - loss: 0.4713 - accuracy: 0.7709\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 968us/step - loss: 0.4687 - accuracy: 0.7690\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 731us/step - loss: 0.4670 - accuracy: 0.7721\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 709us/step - loss: 0.4651 - accuracy: 0.7765\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 787us/step - loss: 0.4634 - accuracy: 0.7797\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 791us/step - loss: 0.4613 - accuracy: 0.7803\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 745us/step - loss: 0.4600 - accuracy: 0.7800\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 704us/step - loss: 0.4588 - accuracy: 0.7828\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 694us/step - loss: 0.4571 - accuracy: 0.7809\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 693us/step - loss: 0.4567 - accuracy: 0.7819\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 686us/step - loss: 0.4551 - accuracy: 0.7797\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 757us/step - loss: 0.4532 - accuracy: 0.7800\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 729us/step - loss: 0.4528 - accuracy: 0.7847\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7850\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 737us/step - loss: 0.4534 - accuracy: 0.7800\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.4500 - accuracy: 0.7863\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 704us/step - loss: 0.4501 - accuracy: 0.7828\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 689us/step - loss: 0.4484 - accuracy: 0.7850\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 687us/step - loss: 0.4489 - accuracy: 0.7837\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 643us/step - loss: 0.4471 - accuracy: 0.7888\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 643us/step - loss: 0.4474 - accuracy: 0.7837\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 652us/step - loss: 0.4456 - accuracy: 0.7863\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 645us/step - loss: 0.4446 - accuracy: 0.7919\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 736us/step - loss: 0.4460 - accuracy: 0.7844\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 745us/step - loss: 0.4439 - accuracy: 0.7847\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7853\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 706us/step - loss: 0.4439 - accuracy: 0.7856\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 694us/step - loss: 0.4428 - accuracy: 0.7884\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 664us/step - loss: 0.4414 - accuracy: 0.7903\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 672us/step - loss: 0.4432 - accuracy: 0.7834\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 649us/step - loss: 0.4411 - accuracy: 0.7881\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 645us/step - loss: 0.4407 - accuracy: 0.7859\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 679us/step - loss: 0.4400 - accuracy: 0.7906\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 686us/step - loss: 0.4393 - accuracy: 0.7872\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 707us/step - loss: 0.4390 - accuracy: 0.7863\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.4406 - accuracy: 0.7903\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 701us/step - loss: 0.4377 - accuracy: 0.7897\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 716us/step - loss: 0.4376 - accuracy: 0.7878\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 674us/step - loss: 0.4376 - accuracy: 0.7906\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 702us/step - loss: 0.4369 - accuracy: 0.7884\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 689us/step - loss: 0.4360 - accuracy: 0.7922\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 697us/step - loss: 0.4361 - accuracy: 0.7878\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.4355 - accuracy: 0.7866\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 694us/step - loss: 0.4348 - accuracy: 0.7878\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 672us/step - loss: 0.4357 - accuracy: 0.7863\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 689us/step - loss: 0.4355 - accuracy: 0.7863\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 675us/step - loss: 0.4354 - accuracy: 0.7891\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 702us/step - loss: 0.4342 - accuracy: 0.7891\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 699us/step - loss: 0.4329 - accuracy: 0.7878\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 738us/step - loss: 0.4325 - accuracy: 0.7932\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 703us/step - loss: 0.4324 - accuracy: 0.7881\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 706us/step - loss: 0.4319 - accuracy: 0.7941\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 719us/step - loss: 0.4330 - accuracy: 0.7922\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 682us/step - loss: 0.4318 - accuracy: 0.7910\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 645us/step - loss: 0.4324 - accuracy: 0.7916\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 641us/step - loss: 0.4312 - accuracy: 0.7919\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 647us/step - loss: 0.4309 - accuracy: 0.7919\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 648us/step - loss: 0.4302 - accuracy: 0.7954\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 655us/step - loss: 0.4317 - accuracy: 0.7922\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 886us/step - loss: 0.4309 - accuracy: 0.7916\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 645us/step - loss: 0.4285 - accuracy: 0.7954\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 687us/step - loss: 0.4304 - accuracy: 0.7884\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 656us/step - loss: 0.4296 - accuracy: 0.7888\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 649us/step - loss: 0.4286 - accuracy: 0.7888\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 645us/step - loss: 0.4285 - accuracy: 0.7925\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 687us/step - loss: 0.4286 - accuracy: 0.7900\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 673us/step - loss: 0.4284 - accuracy: 0.7922\n",
      "250/250 [==============================] - 0s 500us/step - loss: 0.4887 - accuracy: 0.7616\n",
      "250/250 [==============================] - 0s 418us/step\n",
      "[[4878 1492]\n",
      " [ 415 1215]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84      6370\n",
      "           1       0.45      0.75      0.56      1630\n",
      "\n",
      "    accuracy                           0.76      8000\n",
      "   macro avg       0.69      0.76      0.70      8000\n",
      "weighted avg       0.83      0.76      0.78      8000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN(X_sm, X_test,y_sm, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, 407)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = new_df[new_df.Exited==0]\n",
    "df_1 = new_df[new_df.Exited==1]\n",
    "len(df_0), len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1593//407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ensemble = []\n",
    "for i in range(3):\n",
    "    df_ensemble = pd.concat([df_0.sample(407), df_1])\n",
    "    lst_ensemble.append(df_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>0.414</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.583684</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.418</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.575815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094541</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.152992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.256798</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.482578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7551</th>\n",
       "      <td>0.552</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.533958</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.743461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>0.168</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367787</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7223</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.616134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>0.720</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.373287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.467497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470924</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "1227        0.414  0.135135     0.7  0.583684       0.333333          1   \n",
       "4998        0.418  0.297297     0.7  0.575815       0.000000          1   \n",
       "2892        0.502  0.351351     0.3  0.000000       0.333333          1   \n",
       "7090        0.502  0.391892     0.1  0.256798       0.333333          0   \n",
       "7551        0.552  0.256757     0.2  0.533958       0.333333          1   \n",
       "...           ...       ...     ...       ...            ...        ...   \n",
       "8379        0.168  0.500000     0.6  0.000000       0.000000          0   \n",
       "7223        0.898  0.175676     0.9  0.616134       0.000000          0   \n",
       "1046        0.914  0.324324     0.1  0.000000       0.000000          1   \n",
       "1487        0.720  0.445946     0.4  0.373287       0.000000          0   \n",
       "6279        0.814  0.500000     0.9  0.467497       1.000000          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "1227               0         0.921619                  0                0   \n",
       "4998               1         0.094541                  0                1   \n",
       "2892               0         0.152992                  0                0   \n",
       "7090               1         0.482578                  0                0   \n",
       "7551               0         0.743461                  0                0   \n",
       "...              ...              ...                ...              ...   \n",
       "8379               1         0.367787                  0                1   \n",
       "7223               1         0.443009                  1                0   \n",
       "1046               0         0.082453                  0                1   \n",
       "1487               1         0.707012                  0                1   \n",
       "6279               0         0.470924                  0                1   \n",
       "\n",
       "      Gender_Male  Exited  \n",
       "1227            0       0  \n",
       "4998            0       0  \n",
       "2892            1       0  \n",
       "7090            1       0  \n",
       "7551            0       0  \n",
       "...           ...     ...  \n",
       "8379            1       1  \n",
       "7223            1       1  \n",
       "1046            0       1  \n",
       "1487            0       1  \n",
       "6279            0       1  \n",
       "\n",
       "[814 rows x 12 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_ensemble[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 1s 849us/step - loss: 0.6920 - accuracy: 0.5295\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 765us/step - loss: 0.6874 - accuracy: 0.5577\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 722us/step - loss: 0.6838 - accuracy: 0.5811\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 761us/step - loss: 0.6807 - accuracy: 0.5885\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 737us/step - loss: 0.6771 - accuracy: 0.6118\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 729us/step - loss: 0.6733 - accuracy: 0.6253\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.6686 - accuracy: 0.6425\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.6633 - accuracy: 0.6437\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 724us/step - loss: 0.6577 - accuracy: 0.6486\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 713us/step - loss: 0.6524 - accuracy: 0.6572\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 716us/step - loss: 0.6463 - accuracy: 0.6609\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.6413 - accuracy: 0.6634\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 713us/step - loss: 0.6364 - accuracy: 0.6720\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 726us/step - loss: 0.6319 - accuracy: 0.6708\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 734us/step - loss: 0.6281 - accuracy: 0.6757\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 716us/step - loss: 0.6248 - accuracy: 0.6757\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.6219 - accuracy: 0.6843\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 708us/step - loss: 0.6191 - accuracy: 0.6720\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 723us/step - loss: 0.6155 - accuracy: 0.6794\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.6129 - accuracy: 0.6794\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 716us/step - loss: 0.6112 - accuracy: 0.6794\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6089 - accuracy: 0.6818\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.6079 - accuracy: 0.6855\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.6058 - accuracy: 0.6843\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.6040 - accuracy: 0.6867\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 735us/step - loss: 0.6030 - accuracy: 0.6867\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.6011 - accuracy: 0.6843\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 699us/step - loss: 0.5992 - accuracy: 0.6880\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5984 - accuracy: 0.6855\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 682us/step - loss: 0.5971 - accuracy: 0.6867\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 704us/step - loss: 0.5963 - accuracy: 0.6880\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 719us/step - loss: 0.5953 - accuracy: 0.6855\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.6916\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 712us/step - loss: 0.5925 - accuracy: 0.6941\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 735us/step - loss: 0.5916 - accuracy: 0.6830\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 725us/step - loss: 0.5904 - accuracy: 0.6892\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 701us/step - loss: 0.5896 - accuracy: 0.6855\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 708us/step - loss: 0.5879 - accuracy: 0.6892\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 733us/step - loss: 0.5875 - accuracy: 0.6867\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 693us/step - loss: 0.5869 - accuracy: 0.6867\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5857 - accuracy: 0.6892\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 705us/step - loss: 0.5846 - accuracy: 0.6855\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 696us/step - loss: 0.5834 - accuracy: 0.6867\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 681us/step - loss: 0.5826 - accuracy: 0.6880\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 709us/step - loss: 0.5815 - accuracy: 0.6892\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 700us/step - loss: 0.5812 - accuracy: 0.6929\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 696us/step - loss: 0.5801 - accuracy: 0.6966\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 704us/step - loss: 0.5795 - accuracy: 0.6904\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.6892\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 733us/step - loss: 0.5771 - accuracy: 0.6916\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 727us/step - loss: 0.5781 - accuracy: 0.6953\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 725us/step - loss: 0.5757 - accuracy: 0.6966\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.5754 - accuracy: 0.6953\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 735us/step - loss: 0.5745 - accuracy: 0.6929\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5733 - accuracy: 0.6978\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 756us/step - loss: 0.5725 - accuracy: 0.6929\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5709 - accuracy: 0.7002\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 866us/step - loss: 0.5705 - accuracy: 0.6990\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 863us/step - loss: 0.5697 - accuracy: 0.6966\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7002\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.6966\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 833us/step - loss: 0.5677 - accuracy: 0.7027\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5667 - accuracy: 0.7027\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 716us/step - loss: 0.5659 - accuracy: 0.6966\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 705us/step - loss: 0.5650 - accuracy: 0.6990\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 717us/step - loss: 0.5644 - accuracy: 0.7076\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 741us/step - loss: 0.5631 - accuracy: 0.7088\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 772us/step - loss: 0.5640 - accuracy: 0.7064\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 683us/step - loss: 0.5622 - accuracy: 0.7027\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 747us/step - loss: 0.5607 - accuracy: 0.7027\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 771us/step - loss: 0.5599 - accuracy: 0.7088\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 739us/step - loss: 0.5601 - accuracy: 0.7064\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 699us/step - loss: 0.5587 - accuracy: 0.7101\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.5585 - accuracy: 0.7076\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 702us/step - loss: 0.5574 - accuracy: 0.7113\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 712us/step - loss: 0.5559 - accuracy: 0.7113\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 752us/step - loss: 0.5550 - accuracy: 0.7125\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.5542 - accuracy: 0.7088\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 727us/step - loss: 0.5537 - accuracy: 0.7199\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 708us/step - loss: 0.5527 - accuracy: 0.7150\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 717us/step - loss: 0.5523 - accuracy: 0.7150\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 721us/step - loss: 0.5514 - accuracy: 0.7260\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.7199\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 677us/step - loss: 0.5496 - accuracy: 0.7138\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 690us/step - loss: 0.5484 - accuracy: 0.7199\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 679us/step - loss: 0.5477 - accuracy: 0.7162\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7199\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 741us/step - loss: 0.5469 - accuracy: 0.7248\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 702us/step - loss: 0.5458 - accuracy: 0.7285\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 728us/step - loss: 0.5456 - accuracy: 0.7199\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 734us/step - loss: 0.5452 - accuracy: 0.7236\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 701us/step - loss: 0.5446 - accuracy: 0.7211\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 720us/step - loss: 0.5428 - accuracy: 0.7211\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 708us/step - loss: 0.5424 - accuracy: 0.7273\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.5414 - accuracy: 0.7273\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.5401 - accuracy: 0.7297\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5394 - accuracy: 0.7236\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 686us/step - loss: 0.5404 - accuracy: 0.7224\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 698us/step - loss: 0.5381 - accuracy: 0.7285\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 668us/step - loss: 0.5379 - accuracy: 0.7260\n",
      "250/250 [==============================] - 0s 497us/step - loss: 0.5663 - accuracy: 0.7061\n",
      "250/250 [==============================] - 0s 413us/step\n",
      "[[4517 1853]\n",
      " [ 498 1132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.79      6370\n",
      "           1       0.38      0.69      0.49      1630\n",
      "\n",
      "    accuracy                           0.71      8000\n",
      "   macro avg       0.64      0.70      0.64      8000\n",
      "weighted avg       0.79      0.71      0.73      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = lst_ensemble[0].drop(\"Exited\", axis=1)\n",
    "y = lst_ensemble[0][\"Exited\"]\n",
    "y_pred1= ANN(X, X_test,y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 874us/step - loss: 0.6888 - accuracy: 0.5479\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 777us/step - loss: 0.6837 - accuracy: 0.5553\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 736us/step - loss: 0.6788 - accuracy: 0.5565\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 717us/step - loss: 0.6743 - accuracy: 0.5860\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 696us/step - loss: 0.6703 - accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 689us/step - loss: 0.6672 - accuracy: 0.6167\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 712us/step - loss: 0.6649 - accuracy: 0.6265\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 699us/step - loss: 0.6625 - accuracy: 0.6290\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 688us/step - loss: 0.6605 - accuracy: 0.6302\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.6588 - accuracy: 0.6327\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 708us/step - loss: 0.6569 - accuracy: 0.6388\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 705us/step - loss: 0.6553 - accuracy: 0.6302\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6351\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 722us/step - loss: 0.6525 - accuracy: 0.6425\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 702us/step - loss: 0.6504 - accuracy: 0.6486\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 704us/step - loss: 0.6499 - accuracy: 0.6536\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 730us/step - loss: 0.6481 - accuracy: 0.6560\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.6462 - accuracy: 0.6523\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 738us/step - loss: 0.6453 - accuracy: 0.6585\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 723us/step - loss: 0.6440 - accuracy: 0.6609\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 719us/step - loss: 0.6425 - accuracy: 0.6597\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 723us/step - loss: 0.6416 - accuracy: 0.6572\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.6401 - accuracy: 0.6585\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 720us/step - loss: 0.6383 - accuracy: 0.6609\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 731us/step - loss: 0.6378 - accuracy: 0.6622\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 732us/step - loss: 0.6364 - accuracy: 0.6622\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.6361 - accuracy: 0.6634\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 719us/step - loss: 0.6347 - accuracy: 0.6622\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 692us/step - loss: 0.6337 - accuracy: 0.6622\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 726us/step - loss: 0.6321 - accuracy: 0.6634\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 714us/step - loss: 0.6317 - accuracy: 0.6622\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 740us/step - loss: 0.6311 - accuracy: 0.6671\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.6293 - accuracy: 0.6671\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.6280 - accuracy: 0.6658\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 706us/step - loss: 0.6274 - accuracy: 0.6634\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 684us/step - loss: 0.6263 - accuracy: 0.6683\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 700us/step - loss: 0.6255 - accuracy: 0.6695\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 717us/step - loss: 0.6251 - accuracy: 0.6683\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.6236 - accuracy: 0.6683\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 742us/step - loss: 0.6227 - accuracy: 0.6683\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6683\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 775us/step - loss: 0.6205 - accuracy: 0.6732\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 751us/step - loss: 0.6199 - accuracy: 0.6646\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.6187 - accuracy: 0.6622\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 713us/step - loss: 0.6183 - accuracy: 0.6683\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 740us/step - loss: 0.6167 - accuracy: 0.6658\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 726us/step - loss: 0.6174 - accuracy: 0.6732\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.6152 - accuracy: 0.6683\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 724us/step - loss: 0.6149 - accuracy: 0.6683\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.6141 - accuracy: 0.6781\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 714us/step - loss: 0.6125 - accuracy: 0.6744\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 675us/step - loss: 0.6123 - accuracy: 0.6732\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.6110 - accuracy: 0.6769\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 689us/step - loss: 0.6110 - accuracy: 0.6830\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 692us/step - loss: 0.6094 - accuracy: 0.6781\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 696us/step - loss: 0.6098 - accuracy: 0.6732\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 685us/step - loss: 0.6079 - accuracy: 0.6781\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.6073 - accuracy: 0.6744\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.6063 - accuracy: 0.6806\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.6057 - accuracy: 0.6744\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 681us/step - loss: 0.6045 - accuracy: 0.6781\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 691us/step - loss: 0.6046 - accuracy: 0.6818\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 684us/step - loss: 0.6035 - accuracy: 0.6806\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 698us/step - loss: 0.6022 - accuracy: 0.6855\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 699us/step - loss: 0.6013 - accuracy: 0.6781\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 709us/step - loss: 0.6011 - accuracy: 0.6855\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 690us/step - loss: 0.5997 - accuracy: 0.6781\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.6855\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 708us/step - loss: 0.5978 - accuracy: 0.6806\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.5970 - accuracy: 0.6892\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5961 - accuracy: 0.6867\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5962 - accuracy: 0.6781\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 730us/step - loss: 0.5942 - accuracy: 0.6892\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 726us/step - loss: 0.5935 - accuracy: 0.6904\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 698us/step - loss: 0.5933 - accuracy: 0.6867\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 709us/step - loss: 0.5920 - accuracy: 0.6929\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 713us/step - loss: 0.5914 - accuracy: 0.6929\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 691us/step - loss: 0.5902 - accuracy: 0.6978\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 690us/step - loss: 0.5891 - accuracy: 0.6929\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 684us/step - loss: 0.5887 - accuracy: 0.6929\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5877 - accuracy: 0.6941\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.5882 - accuracy: 0.6916\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.5857 - accuracy: 0.7002\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 713us/step - loss: 0.5833 - accuracy: 0.7027\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 702us/step - loss: 0.5803 - accuracy: 0.7027\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 720us/step - loss: 0.5786 - accuracy: 0.6990\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5769 - accuracy: 0.6990\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.5745 - accuracy: 0.7039\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 732us/step - loss: 0.5732 - accuracy: 0.7101\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.5704 - accuracy: 0.7101\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.5676 - accuracy: 0.7125\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.5653 - accuracy: 0.7150\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.5618 - accuracy: 0.7297\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 687us/step - loss: 0.5592 - accuracy: 0.7162\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 705us/step - loss: 0.5568 - accuracy: 0.7371\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 696us/step - loss: 0.5533 - accuracy: 0.7248\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5514 - accuracy: 0.7371\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 682us/step - loss: 0.5473 - accuracy: 0.7285\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 689us/step - loss: 0.5456 - accuracy: 0.7334\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 705us/step - loss: 0.5412 - accuracy: 0.7334\n",
      "250/250 [==============================] - 0s 622us/step - loss: 0.5447 - accuracy: 0.7203\n",
      "250/250 [==============================] - 0s 440us/step\n",
      "[[4600 1770]\n",
      " [ 468 1162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80      6370\n",
      "           1       0.40      0.71      0.51      1630\n",
      "\n",
      "    accuracy                           0.72      8000\n",
      "   macro avg       0.65      0.72      0.66      8000\n",
      "weighted avg       0.80      0.72      0.74      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = lst_ensemble[1].drop(\"Exited\", axis=1)\n",
    "y = lst_ensemble[1][\"Exited\"]\n",
    "y_pred2 = ANN(X, X_test,y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 851us/step - loss: 0.6927 - accuracy: 0.5012\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 755us/step - loss: 0.6897 - accuracy: 0.5074\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 764us/step - loss: 0.6881 - accuracy: 0.5197\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 733us/step - loss: 0.6863 - accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 708us/step - loss: 0.6845 - accuracy: 0.5725\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.6827 - accuracy: 0.5848\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 701us/step - loss: 0.6807 - accuracy: 0.5835\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 721us/step - loss: 0.6786 - accuracy: 0.5909\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.6767 - accuracy: 0.5934\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.6741 - accuracy: 0.6093\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 692us/step - loss: 0.6716 - accuracy: 0.6192\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 691us/step - loss: 0.6697 - accuracy: 0.6155\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 698us/step - loss: 0.6665 - accuracy: 0.6216\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 693us/step - loss: 0.6637 - accuracy: 0.6327\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 693us/step - loss: 0.6609 - accuracy: 0.6302\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 680us/step - loss: 0.6581 - accuracy: 0.6302\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 685us/step - loss: 0.6543 - accuracy: 0.6314\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 692us/step - loss: 0.6481 - accuracy: 0.6314\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.6405 - accuracy: 0.6425\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 695us/step - loss: 0.6311 - accuracy: 0.6425\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 719us/step - loss: 0.6230 - accuracy: 0.6597\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 693us/step - loss: 0.6206 - accuracy: 0.6658\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 700us/step - loss: 0.6169 - accuracy: 0.6671\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 691us/step - loss: 0.6137 - accuracy: 0.6708\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6720\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 741us/step - loss: 0.6087 - accuracy: 0.6781\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 704us/step - loss: 0.6067 - accuracy: 0.6744\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.6051 - accuracy: 0.6781\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 717us/step - loss: 0.6012 - accuracy: 0.6830\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 699us/step - loss: 0.5994 - accuracy: 0.6830\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 709us/step - loss: 0.5970 - accuracy: 0.6892\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.5954 - accuracy: 0.6867\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 701us/step - loss: 0.5941 - accuracy: 0.6880\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 686us/step - loss: 0.5925 - accuracy: 0.6880\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 686us/step - loss: 0.5902 - accuracy: 0.6892\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5886 - accuracy: 0.6818\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5880 - accuracy: 0.6904\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 771us/step - loss: 0.5851 - accuracy: 0.6916\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 667us/step - loss: 0.5838 - accuracy: 0.6880\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 690us/step - loss: 0.5827 - accuracy: 0.6916\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 694us/step - loss: 0.5813 - accuracy: 0.6929\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 705us/step - loss: 0.5793 - accuracy: 0.6929\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 697us/step - loss: 0.5777 - accuracy: 0.6966\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 711us/step - loss: 0.5761 - accuracy: 0.6953\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 703us/step - loss: 0.5749 - accuracy: 0.6953\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 710us/step - loss: 0.5759 - accuracy: 0.6916\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 734us/step - loss: 0.5732 - accuracy: 0.6966\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 720us/step - loss: 0.5717 - accuracy: 0.6904\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 736us/step - loss: 0.5704 - accuracy: 0.6929\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7015\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 727us/step - loss: 0.5683 - accuracy: 0.6990\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 706us/step - loss: 0.5689 - accuracy: 0.6929\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 683us/step - loss: 0.5677 - accuracy: 0.7027\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 681us/step - loss: 0.5662 - accuracy: 0.6990\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 693us/step - loss: 0.5664 - accuracy: 0.7064\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 682us/step - loss: 0.5654 - accuracy: 0.7064\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 683us/step - loss: 0.5630 - accuracy: 0.7002\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7015\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 721us/step - loss: 0.5614 - accuracy: 0.7052\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 712us/step - loss: 0.5611 - accuracy: 0.7039\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 739us/step - loss: 0.5590 - accuracy: 0.7002\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 725us/step - loss: 0.5596 - accuracy: 0.7088\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 714us/step - loss: 0.5589 - accuracy: 0.6966\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 720us/step - loss: 0.5564 - accuracy: 0.7052\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 741us/step - loss: 0.5562 - accuracy: 0.7076\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 706us/step - loss: 0.5546 - accuracy: 0.7002\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 700us/step - loss: 0.5544 - accuracy: 0.7027\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 690us/step - loss: 0.5530 - accuracy: 0.6990\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 689us/step - loss: 0.5526 - accuracy: 0.7015\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 686us/step - loss: 0.5516 - accuracy: 0.7064\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 683us/step - loss: 0.5524 - accuracy: 0.7002\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 691us/step - loss: 0.5507 - accuracy: 0.6966\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 719us/step - loss: 0.5497 - accuracy: 0.7039\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 700us/step - loss: 0.5494 - accuracy: 0.7039\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 736us/step - loss: 0.5480 - accuracy: 0.7039\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 720us/step - loss: 0.5460 - accuracy: 0.7113\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 714us/step - loss: 0.5461 - accuracy: 0.7088\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 778us/step - loss: 0.5455 - accuracy: 0.7076\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 725us/step - loss: 0.5438 - accuracy: 0.7125\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 709us/step - loss: 0.5430 - accuracy: 0.7150\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 698us/step - loss: 0.5445 - accuracy: 0.7064\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 707us/step - loss: 0.5416 - accuracy: 0.7138\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 747us/step - loss: 0.5419 - accuracy: 0.7101\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.7113\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5393 - accuracy: 0.7162\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 729us/step - loss: 0.5387 - accuracy: 0.7138\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 712us/step - loss: 0.5375 - accuracy: 0.7199\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 726us/step - loss: 0.5369 - accuracy: 0.7162\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 737us/step - loss: 0.5367 - accuracy: 0.7199\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 723us/step - loss: 0.5382 - accuracy: 0.7125\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 708us/step - loss: 0.5344 - accuracy: 0.7174\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 724us/step - loss: 0.5331 - accuracy: 0.7138\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.7187\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 725us/step - loss: 0.5318 - accuracy: 0.7285\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 734us/step - loss: 0.5329 - accuracy: 0.7150\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 733us/step - loss: 0.5314 - accuracy: 0.7310\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 715us/step - loss: 0.5296 - accuracy: 0.7285\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 729us/step - loss: 0.5299 - accuracy: 0.7224\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 713us/step - loss: 0.5265 - accuracy: 0.7260\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 706us/step - loss: 0.5266 - accuracy: 0.7334\n",
      "250/250 [==============================] - 0s 495us/step - loss: 0.5433 - accuracy: 0.7297\n",
      "250/250 [==============================] - 0s 420us/step\n",
      "[[4739 1631]\n",
      " [ 531 1099]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81      6370\n",
      "           1       0.40      0.67      0.50      1630\n",
      "\n",
      "    accuracy                           0.73      8000\n",
      "   macro avg       0.65      0.71      0.66      8000\n",
      "weighted avg       0.80      0.73      0.75      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = lst_ensemble[2].drop(\"Exited\", axis=1)\n",
    "y = lst_ensemble[2][\"Exited\"]\n",
    "y_pred3 = ANN(X, X_test,y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_pred1.copy()\n",
    "for i in range(len(y_pred_final)):\n",
    "    num = y_pred1[i] + y_pred2[i] + y_pred3[i]\n",
    "    if num >= 1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.63      0.75      6370\n",
      "           1       0.35      0.78      0.48      1630\n",
      "\n",
      "    accuracy                           0.66      8000\n",
      "   macro avg       0.63      0.70      0.62      8000\n",
      "weighted avg       0.80      0.66      0.69      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a word2vec model on the Amazon datasets in kaggle. Once you train a model on this, find the words most similar to 'awful' and find similarities between the following word tuples: ('good', 'great'), ('slow','steady')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text= df.review.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [one, of, the, other, reviewers, has, mentione...\n",
       "1    [wonderful, little, production, br, br, the, f...\n",
       "2    [thought, this, was, wonderful, way, to, spend...\n",
       "3    [basically, there, family, where, little, boy,...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'you',\n",
       " 'll',\n",
       " 'be',\n",
       " 'hooked',\n",
       " 'they',\n",
       " 'are',\n",
       " 'right',\n",
       " 'as',\n",
       " 'this',\n",
       " 'is',\n",
       " 'exactly',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'with',\n",
       " 'me',\n",
       " 'br',\n",
       " 'br',\n",
       " 'the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'about',\n",
       " 'oz',\n",
       " 'was',\n",
       " 'its',\n",
       " 'brutality',\n",
       " 'and',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'violence',\n",
       " 'which',\n",
       " 'set',\n",
       " 'in',\n",
       " 'right',\n",
       " 'from',\n",
       " 'the',\n",
       " 'word',\n",
       " 'go',\n",
       " 'trust',\n",
       " 'me',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'show',\n",
       " 'for',\n",
       " 'the',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'or',\n",
       " 'timid',\n",
       " 'this',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'no',\n",
       " 'punches',\n",
       " 'with',\n",
       " 'regards',\n",
       " 'to',\n",
       " 'drugs',\n",
       " 'sex',\n",
       " 'or',\n",
       " 'violence',\n",
       " 'its',\n",
       " 'is',\n",
       " 'hardcore',\n",
       " 'in',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word',\n",
       " 'br',\n",
       " 'br',\n",
       " 'it',\n",
       " 'is',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'as',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary',\n",
       " 'it',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'emerald',\n",
       " 'city',\n",
       " 'an',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prison',\n",
       " 'where',\n",
       " 'all',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'have',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'and',\n",
       " 'face',\n",
       " 'inwards',\n",
       " 'so',\n",
       " 'privacy',\n",
       " 'is',\n",
       " 'not',\n",
       " 'high',\n",
       " 'on',\n",
       " 'the',\n",
       " 'agenda',\n",
       " 'em',\n",
       " 'city',\n",
       " 'is',\n",
       " 'home',\n",
       " 'to',\n",
       " 'many',\n",
       " 'aryans',\n",
       " 'muslims',\n",
       " 'gangstas',\n",
       " 'latinos',\n",
       " 'christians',\n",
       " 'italians',\n",
       " 'irish',\n",
       " 'and',\n",
       " 'more',\n",
       " 'so',\n",
       " 'scuffles',\n",
       " 'death',\n",
       " 'stares',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'and',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'are',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away',\n",
       " 'br',\n",
       " 'br',\n",
       " 'would',\n",
       " 'say',\n",
       " 'the',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'of',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'where',\n",
       " 'other',\n",
       " 'shows',\n",
       " 'wouldn',\n",
       " 'dare',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'for',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " 'forget',\n",
       " 'charm',\n",
       " 'forget',\n",
       " 'romance',\n",
       " 'oz',\n",
       " 'doesn',\n",
       " 'mess',\n",
       " 'around',\n",
       " 'the',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'as',\n",
       " 'so',\n",
       " 'nasty',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surreal',\n",
       " 'couldn',\n",
       " 'say',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'it',\n",
       " 'but',\n",
       " 'as',\n",
       " 'watched',\n",
       " 'more',\n",
       " 'developed',\n",
       " 'taste',\n",
       " 'for',\n",
       " 'oz',\n",
       " 'and',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " 'not',\n",
       " 'just',\n",
       " 'violence',\n",
       " 'but',\n",
       " 'injustice',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " 'who',\n",
       " 'll',\n",
       " 'be',\n",
       " 'sold',\n",
       " 'out',\n",
       " 'for',\n",
       " 'nickel',\n",
       " 'inmates',\n",
       " 'who',\n",
       " 'll',\n",
       " 'kill',\n",
       " 'on',\n",
       " 'order',\n",
       " 'and',\n",
       " 'get',\n",
       " 'away',\n",
       " 'with',\n",
       " 'it',\n",
       " 'well',\n",
       " 'mannered',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'being',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'to',\n",
       " 'their',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'or',\n",
       " 'prison',\n",
       " 'experience',\n",
       " 'watching',\n",
       " 'oz',\n",
       " 'you',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'with',\n",
       " 'what',\n",
       " 'is',\n",
       " 'uncomfortable',\n",
       " 'viewing',\n",
       " 'thats',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'your',\n",
       " 'darker',\n",
       " 'side']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text.loc[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42464068, 55882335)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.8957457542419434),\n",
       " ('horrible', 0.8515822291374207),\n",
       " ('dreadful', 0.8344962000846863),\n",
       " ('atrocious', 0.8152419328689575),\n",
       " ('lousy', 0.7886127233505249),\n",
       " ('horrendous', 0.780099630355835),\n",
       " ('horrid', 0.7773901224136353),\n",
       " ('pathetic', 0.7631842494010925),\n",
       " ('abysmal', 0.7559261918067932),\n",
       " ('bad', 0.7551819086074829)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"awful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.730798"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"good\", w2=\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45198363"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"slow\", w2=\"steady\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie reviews are present as individual text file (one file per review) in review folder. <br>\n",
    "\n",
    "Folder structure looks like this, <br>\n",
    "\n",
    "reviews <br>\n",
    "    |__ positive <br>\n",
    "        |__pos_1.txt <br>\n",
    "        |__pos_2.txt <br>\n",
    "        |__pos_3.txt <br>\n",
    "    |__ negative\n",
    "        |__neg_1.txt <br>\n",
    "        |__neg_2.txt <br>\n",
    "        |__neg_3.txt <br>\n",
    "You need to read these reviews using tf.data.Dataset and perform following transformations, <br>\n",
    "\n",
    "Read text review and generate a label from folder name. your dataset should have review text and label as a tuple <br>\n",
    "Filter blank text review. Two files are blank in this dataset <br>\n",
    "Do all of the above transformations in single line of code. Also shuffle all the reviews <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 17:22:33.478132: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 17:22:38.807278: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "reviews_dataset = tf.data.Dataset.list_files('reviews/*/*', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(reviews_dataset)*0.8)\n",
    "train_dataset = reviews_dataset.take(train_size)\n",
    "test_dataset = reviews_dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def extract_review_and_label(file_path):\n",
    "    return tf.io.read_file(file_path), tf.strings.split(file_path, os.path.sep)[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b\"This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 or 8 years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, and it's continued its decline further to the complete waste of time it is today.<br /><br />It's truly disgraceful how far this show has fallen. The writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn't still be on the air. I find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. How can one recognize such brilliance and then see fit to replace it with such mediocrity? I felt I must give 2 stars out of respect for the original cast that made this show such a huge success. As it is now, the show is just awful. I can't believe it's still on the air.\\n\"\n",
      "Label: b'negative'\n",
      "Review: b\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\\n\"\n",
      "Label: b'positive'\n",
      "Review: b\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\\n\"\n",
      "Label: b'negative'\n"
     ]
    }
   ],
   "source": [
    "final_train_dataset = train_dataset.map(extract_review_and_label).filter(lambda review, label: review!=\"\").shuffle(3).prefetch(tf.data.AUTOTUNE).cache()\n",
    "final_test_dataset = test_dataset.map(extract_review_and_label).filter(lambda review, label: review!=\"\").shuffle(3)\n",
    "for review, label in final_train_dataset.as_numpy_iterator():\n",
    "    print(\"Review:\",review)\n",
    "    print(\"Label:\",label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff7d574ff54b0f83d103cd6ae016c78af2d72d27cb5ffce6ccc74920cc77be9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
